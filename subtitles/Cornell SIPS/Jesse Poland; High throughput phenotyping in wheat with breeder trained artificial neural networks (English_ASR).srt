1
00:00:00,089 --> 00:00:05,970
this is a production of Cornell

2
00:00:02,218 --> 00:00:12,330
University okay so thank you it's really

3
00:00:05,969 --> 00:00:13,859
nice honor to be back here especially

4
00:00:12,330 --> 00:00:17,698
nice honor to be invited by the graduate

5
00:00:13,859 --> 00:00:20,579
students that's so it was almost just

6
00:00:17,699 --> 00:00:24,150
shy of eight years ago had my defense

7
00:00:20,579 --> 00:00:25,559
right in this room so for all your grad

8
00:00:24,149 --> 00:00:27,059
students in just a few years from now

9
00:00:25,559 --> 00:00:29,250
you could have a bunch of children

10
00:00:27,059 --> 00:00:32,729
running around at home and a bunch of

11
00:00:29,250 --> 00:00:37,710
grad students running around the lab you

12
00:00:32,729 --> 00:00:40,140
could be back here and so also I need to

13
00:00:37,710 --> 00:00:42,450
dedicate this to like Rebecca and Edie

14
00:00:40,140 --> 00:00:44,759
for the inspiration to work on high

15
00:00:42,450 --> 00:00:46,140
throughput phenotyping we had this great

16
00:00:44,759 --> 00:00:49,619
idea to work on the maze named

17
00:00:46,140 --> 00:00:52,679
populations for disease resistance right

18
00:00:49,619 --> 00:00:55,288
so I literally calculated up I literally

19
00:00:52,679 --> 00:00:59,119
spent like one and a half months of my

20
00:00:55,289 --> 00:01:02,929
life looking at maze lesions and

21
00:00:59,119 --> 00:01:05,789
recording percentage disease leaf area

22
00:01:02,929 --> 00:01:09,170
for thousands of plots over and over and

23
00:01:05,789 --> 00:01:10,859
over again so there's a lot of

24
00:01:09,170 --> 00:01:16,810
inspiration to do something more

25
00:01:10,858 --> 00:01:18,019
efficiently than walking around Thanks

26
00:01:16,810 --> 00:01:20,340
[Music]

27
00:01:18,019 --> 00:01:23,248
okay so I always put everything in the

28
00:01:20,340 --> 00:01:25,380
context of where we need to be in the

29
00:01:23,248 --> 00:01:28,739
next couple of decades so he projected

30
00:01:25,379 --> 00:01:29,908
60% increase in demand for wheat if we

31
00:01:28,739 --> 00:01:32,039
leave everything with climate change

32
00:01:29,909 --> 00:01:34,618
hotter climates you'll push that down

33
00:01:32,039 --> 00:01:37,109
20% so we need about a 2% gain per year

34
00:01:34,618 --> 00:01:39,289
and current currently wheats we does

35
00:01:37,108 --> 00:01:43,109
that most major crops are about a 1%

36
00:01:39,289 --> 00:01:49,250
gain per year so in the

37
00:01:43,109 --> 00:01:52,170
context to the breeding cycle bingo you

38
00:01:49,250 --> 00:01:55,079
know this thing is stuck at the top okay

39
00:01:52,170 --> 00:01:56,490
whatever so in the context of breeding

40
00:01:55,079 --> 00:01:57,719
cycle we're trying to make this cycle go

41
00:01:56,489 --> 00:02:00,239
faster more efficient so we're making

42
00:01:57,719 --> 00:02:03,299
crosses you know early stages you're

43
00:02:00,239 --> 00:02:04,919
evaluating for diseases later stages

44
00:02:03,299 --> 00:02:08,789
your value for yield and then really

45
00:02:04,920 --> 00:02:10,439
late on the quality you pick the best

46
00:02:08,789 --> 00:02:12,419
performing stuff and then you advance to

47
00:02:10,439 --> 00:02:14,609
the next cycle so we really work in this

48
00:02:12,419 --> 00:02:16,109
this mindset this mantra of if we can

49
00:02:14,610 --> 00:02:20,490
make the breeding cycle go bigger and

50
00:02:16,110 --> 00:02:22,080
faster then we can lead to more more

51
00:02:20,490 --> 00:02:24,180
rapid improve riding so that's why we

52
00:02:22,080 --> 00:02:26,489
work a lot of genomic selection we work

53
00:02:24,180 --> 00:02:30,510
a lot on high throughput phenotyping and

54
00:02:26,489 --> 00:02:31,739
so in this context the genetic gain over

55
00:02:30,509 --> 00:02:33,750
time is a function of a selection

56
00:02:31,739 --> 00:02:34,770
intensity so that you know we need

57
00:02:33,750 --> 00:02:37,169
bigger populations

58
00:02:34,770 --> 00:02:38,189
it's a diminishing returns but that's a

59
00:02:37,169 --> 00:02:40,079
lot of focus on the high-throughput

60
00:02:38,189 --> 00:02:43,319
phenotyping and the genomic selection

61
00:02:40,080 --> 00:02:45,510
can help with with bigger populations

62
00:02:43,319 --> 00:02:47,459
the selection accuracy this is some high

63
00:02:45,509 --> 00:02:49,139
throughput phenotyping we can make more

64
00:02:47,459 --> 00:02:51,539
accurate measurements than you can do by

65
00:02:49,139 --> 00:02:53,939
hand the genetic variance we work a lot

66
00:02:51,539 --> 00:02:55,379
on genetic diversity won't really touch

67
00:02:53,939 --> 00:02:57,900
on that and then the years per cycle

68
00:02:55,379 --> 00:02:59,759
that's also like a one of the components

69
00:02:57,900 --> 00:03:00,870
of working on genomic selection so this

70
00:02:59,759 --> 00:03:02,729
is kind of like putting all their things

71
00:03:00,870 --> 00:03:05,280
together I'm just gonna really focus on

72
00:03:02,729 --> 00:03:06,949
some of the things the fun the fun new

73
00:03:05,280 --> 00:03:10,650
things that we've been doing with

74
00:03:06,949 --> 00:03:12,018
genomic selection recently and so we

75
00:03:10,650 --> 00:03:14,659
really have to define like what is

76
00:03:12,019 --> 00:03:16,590
high-throughput phenotyping okay so

77
00:03:14,659 --> 00:03:19,109
here's how we define high-throughput

78
00:03:16,590 --> 00:03:21,180
it's like gonna be mostly or fully

79
00:03:19,110 --> 00:03:22,980
automated data collection so currently

80
00:03:21,180 --> 00:03:24,840
we're almost there right you like spend

81
00:03:22,979 --> 00:03:28,139
like 15 minutes like collecting data and

82
00:03:24,840 --> 00:03:30,060
then like 15 months like analyzing it so

83
00:03:28,139 --> 00:03:34,259
it's not really high throughput yet in

84
00:03:30,060 --> 00:03:35,909
that sense but we're almost there we

85
00:03:34,259 --> 00:03:37,859
really define it as we have to be able

86
00:03:35,909 --> 00:03:40,079
to do tens of thousands of plots so we

87
00:03:37,860 --> 00:03:41,820
look at the actual breeding programs

88
00:03:40,079 --> 00:03:43,260
they're operating in the thousands and

89
00:03:41,819 --> 00:03:44,909
tens of thousands so if it's not

90
00:03:43,259 --> 00:03:48,049
scalable to that then it's not really

91
00:03:44,909 --> 00:03:50,419
scalable we got to do this in the

92
00:03:48,050 --> 00:03:52,790
like I said it gotta be automated data

93
00:03:50,419 --> 00:03:54,949
processing and data collection and then

94
00:03:52,789 --> 00:03:56,299
I always note that like high-resolution

95
00:03:54,949 --> 00:03:57,348
isn't really high throughput so if

96
00:03:56,300 --> 00:03:59,000
there's one thing I learned at Cornell

97
00:03:57,348 --> 00:04:01,039
it's like the power of big populations

98
00:03:59,000 --> 00:04:02,539
so you don't have to measure things real

99
00:04:01,039 --> 00:04:07,068
accurately you just got to measure them

100
00:04:02,539 --> 00:04:09,199
on a huge population okay so so really

101
00:04:07,068 --> 00:04:10,909
like how do we define what is HTTP it

102
00:04:09,199 --> 00:04:12,859
says up there so one thing is the

103
00:04:10,909 --> 00:04:13,519
breeder's the benchmark see this is dr.

104
00:04:12,860 --> 00:04:15,920
Ravi Singh

105
00:04:13,519 --> 00:04:19,040
he runs the Simic week program he can go

106
00:04:15,919 --> 00:04:22,909
through in an afternoon 4,000 small

107
00:04:19,040 --> 00:04:26,419
plots make really accurate selections

108
00:04:22,910 --> 00:04:28,370
for height for disease for maturity and

109
00:04:26,418 --> 00:04:31,759
so that's your benchmark right right

110
00:04:28,370 --> 00:04:33,439
there okay so this is he says HDPE is is

111
00:04:31,759 --> 00:04:35,659
high throughput painting right so you go

112
00:04:33,439 --> 00:04:37,519
through and paint the ones that are good

113
00:04:35,660 --> 00:04:39,470
and that's what gets selected right so

114
00:04:37,519 --> 00:04:41,000
that's your benchmark right there the

115
00:04:39,470 --> 00:04:43,790
other one is that breeders are

116
00:04:41,000 --> 00:04:45,560
notoriously good is the combination here

117
00:04:43,790 --> 00:04:46,790
at phenotyping meaning like just like

118
00:04:45,560 --> 00:04:48,439
Robbie does he makes really nice

119
00:04:46,790 --> 00:04:51,710
accurate selections for height but

120
00:04:48,439 --> 00:04:52,759
nobody records the data so the point is

121
00:04:51,709 --> 00:04:53,750
that if we're going to build prediction

122
00:04:52,759 --> 00:04:56,240
models you actually have to have like

123
00:04:53,750 --> 00:04:58,220
data numbers to go in to the models and

124
00:04:56,240 --> 00:05:01,129
not just like breeders selecting it was

125
00:04:58,220 --> 00:05:02,300
kept or not okay and then the last one

126
00:05:01,129 --> 00:05:04,339
is like I said the power a big

127
00:05:02,300 --> 00:05:06,829
population so we need to be able to like

128
00:05:04,339 --> 00:05:08,538
apply these systems on populations that

129
00:05:06,829 --> 00:05:10,639
are literally in the tens of thousands

130
00:05:08,538 --> 00:05:13,279
so the semi program for example there's

131
00:05:10,639 --> 00:05:16,909
50,000 new inbred lines generated every

132
00:05:13,279 --> 00:05:19,179
year that go into a field block of some

133
00:05:16,910 --> 00:05:19,180
sort

134
00:05:19,360 --> 00:05:23,419
so in connecting the genotype to the

135
00:05:21,800 --> 00:05:25,400
phenotype we do a lot of this we like

136
00:05:23,418 --> 00:05:26,538
observe a phenotype quantitative

137
00:05:25,399 --> 00:05:30,258
genetics we try and find some

138
00:05:26,538 --> 00:05:31,728
correlation back to the genotype and

139
00:05:30,259 --> 00:05:33,740
then we try and work out the biology of

140
00:05:31,728 --> 00:05:35,418
how that those genes actually turn into

141
00:05:33,740 --> 00:05:36,889
the phenotype we observe I mean of

142
00:05:35,418 --> 00:05:38,329
breeding what we really want to do is

143
00:05:36,889 --> 00:05:40,728
use the genotype to predict the

144
00:05:38,329 --> 00:05:41,930
phenotypes into the next cyclist section

145
00:05:40,728 --> 00:05:43,310
so in the scope of high-throughput

146
00:05:41,930 --> 00:05:45,709
phenotyping what we're really talking

147
00:05:43,310 --> 00:05:46,968
about is some phenotype that predicts

148
00:05:45,709 --> 00:05:49,788
some other phenotype that's more

149
00:05:46,968 --> 00:05:51,680
difficult to measure okay so one example

150
00:05:49,788 --> 00:05:53,269
that you know that I'd like to show is

151
00:05:51,680 --> 00:05:56,180
that canopy temperature is really easy

152
00:05:53,269 --> 00:05:57,680
to measure that under under heat or

153
00:05:56,180 --> 00:06:00,829
drought stress conditions that has a

154
00:05:57,680 --> 00:06:03,918
really strong negative correlation with

155
00:06:00,829 --> 00:06:05,209
you okay so this is just one example of

156
00:06:03,918 --> 00:06:06,829
what we're thinking about in the high

157
00:06:05,209 --> 00:06:08,239
throughput you know so a lot of what we

158
00:06:06,829 --> 00:06:09,740
do in the high throughput phenotyping is

159
00:06:08,240 --> 00:06:12,680
like direct sensor measurements of

160
00:06:09,740 --> 00:06:15,139
something like a vegetation index and so

161
00:06:12,680 --> 00:06:17,329
what you have here is like looking at

162
00:06:15,139 --> 00:06:20,180
the ratio of the green to red to

163
00:06:17,329 --> 00:06:22,459
near-infrared reflectance from that leaf

164
00:06:20,180 --> 00:06:25,848
is a really nice assessment of the

165
00:06:22,459 --> 00:06:29,180
overall health status of that plant

166
00:06:25,848 --> 00:06:31,430
right nitrogen status any disease type

167
00:06:29,180 --> 00:06:33,139
of problems and so we we become that

168
00:06:31,430 --> 00:06:34,699
we've been working on this for several

169
00:06:33,139 --> 00:06:37,538
years this is becoming really routine

170
00:06:34,699 --> 00:06:39,830
especially with the UAVs to measure

171
00:06:37,538 --> 00:06:42,259
literally like this last year we were

172
00:06:39,829 --> 00:06:44,149
able to cover the 50,000 unique

173
00:06:42,259 --> 00:06:45,830
individual plots at multiple time points

174
00:06:44,149 --> 00:06:48,318
on the breeding program so this is

175
00:06:45,829 --> 00:06:50,750
becoming really routine we've done this

176
00:06:48,319 --> 00:06:52,158
with the ground vehicles so I'll just

177
00:06:50,750 --> 00:06:53,449
highlight this here you know we started

178
00:06:52,158 --> 00:06:56,120
out with this ground vehicle it's got

179
00:06:53,449 --> 00:06:59,240
precision GPS on each side here a number

180
00:06:56,120 --> 00:07:01,310
of sensors you we've been working on

181
00:06:59,240 --> 00:07:03,228
these type of platforms for several

182
00:07:01,310 --> 00:07:05,959
years you can drive through the field

183
00:07:03,228 --> 00:07:08,538
like this those sensors are continually

184
00:07:05,959 --> 00:07:10,848
collecting data we can use the GPS to

185
00:07:08,538 --> 00:07:13,938
assign those back to individual plots

186
00:07:10,848 --> 00:07:15,378
and so what that looks like then is you

187
00:07:13,939 --> 00:07:16,849
can traverse back and forth in the field

188
00:07:15,379 --> 00:07:20,119
each one of those being a single data

189
00:07:16,848 --> 00:07:23,399
point you can take those data points we

190
00:07:20,119 --> 00:07:25,199
we have different ways to survey out the

191
00:07:23,399 --> 00:07:29,158
plot coordinate boundaries and then

192
00:07:25,199 --> 00:07:31,710
based on that intersection of the plots

193
00:07:29,158 --> 00:07:34,019
and the data points you can assign those

194
00:07:31,709 --> 00:07:35,218
to individual plots in the field so this

195
00:07:34,019 --> 00:07:37,948
has become over the last couple years

196
00:07:35,218 --> 00:07:41,098
like sort of routine it's becoming very

197
00:07:37,949 --> 00:07:43,619
routine we're also doing it with the

198
00:07:41,098 --> 00:07:48,628
UAVs and so here's an example flying

199
00:07:43,619 --> 00:07:50,249
some of these in India and nice thing

200
00:07:48,629 --> 00:07:51,718
about the UAVs is being able to deploy

201
00:07:50,249 --> 00:07:53,669
them all over the world so we can pack

202
00:07:51,718 --> 00:07:56,248
them up in a suitcase you put these on

203
00:07:53,668 --> 00:07:58,198
you know the field trials and in Mexico

204
00:07:56,249 --> 00:08:00,599
and India all across we can haul them

205
00:07:58,199 --> 00:08:03,028
all across Kansas and so here's like a

206
00:08:00,598 --> 00:08:05,639
false color image of what that looks

207
00:08:03,028 --> 00:08:07,558
like with the near-infrared band and so

208
00:08:05,639 --> 00:08:09,749
from this you can very easily crop out

209
00:08:07,559 --> 00:08:12,180
individual plots get an assessment of

210
00:08:09,749 --> 00:08:13,949
NDVI and then what we've been doing is

211
00:08:12,180 --> 00:08:17,338
incorporating those into prediction

212
00:08:13,949 --> 00:08:18,838
models and so here's just an example the

213
00:08:17,338 --> 00:08:22,408
grad students you can get these papers

214
00:08:18,838 --> 00:08:26,129
and then go read them okay and then

215
00:08:22,408 --> 00:08:29,158
there'll be a quiz after the class and

216
00:08:26,129 --> 00:08:30,658
so with that right we can take these we

217
00:08:29,158 --> 00:08:32,269
can incorporate them into combined

218
00:08:30,658 --> 00:08:34,019
models that have genomic selection

219
00:08:32,269 --> 00:08:36,299
combined with the high throughput

220
00:08:34,019 --> 00:08:39,658
phenotyping data as like two levels of

221
00:08:36,299 --> 00:08:42,000
information onto those onto those small

222
00:08:39,658 --> 00:08:44,009
yield plots and then predicting like

223
00:08:42,000 --> 00:08:46,198
yield as if it was a replicated field

224
00:08:44,009 --> 00:08:47,730
trial but so that's really the that's

225
00:08:46,198 --> 00:08:51,240
really the scope if we were using these

226
00:08:47,730 --> 00:08:53,159
as like secondary correlated traits to

227
00:08:51,240 --> 00:08:54,930
yield we're becoming very high

228
00:08:53,159 --> 00:08:57,389
throughput and efficient in measuring

229
00:08:54,929 --> 00:08:59,789
them across huge number of plots and so

230
00:08:57,389 --> 00:09:03,720
now it's just a matter of optimizing

231
00:08:59,789 --> 00:09:06,929
your prediction models so that's really

232
00:09:03,720 --> 00:09:08,490
where we're at real brief overview of

233
00:09:06,929 --> 00:09:10,078
where we're at with high-throughput

234
00:09:08,490 --> 00:09:12,930
phenotyping for simple things like

235
00:09:10,078 --> 00:09:15,539
vegetation index and so I didn't want to

236
00:09:12,929 --> 00:09:21,689
just highlight that and use that kind of

237
00:09:15,539 --> 00:09:24,719
as the background context of where we're

238
00:09:21,690 --> 00:09:26,639
at for that so this is like that's the

239
00:09:24,720 --> 00:09:28,649
last example like it's the real sample

240
00:09:26,639 --> 00:09:30,600
of directly measuring something like

241
00:09:28,649 --> 00:09:32,789
plant

242
00:09:30,600 --> 00:09:34,230
greenness okay and then using that to

243
00:09:32,789 --> 00:09:35,939
improve and we can we can drastically

244
00:09:34,230 --> 00:09:37,709
improve the prediction models with that

245
00:09:35,940 --> 00:09:41,160
level arm information this is an idea of

246
00:09:37,708 --> 00:09:43,439
like phenotyping from images just

247
00:09:41,159 --> 00:09:45,240
phenotyping flour color okay so that's

248
00:09:43,440 --> 00:09:47,130
basically what we've been doing so this

249
00:09:45,240 --> 00:09:48,959
is just really simple here right if you

250
00:09:47,129 --> 00:09:51,750
take this picture and you apply a red

251
00:09:48,958 --> 00:09:54,268
filter you can see that there's a lot of

252
00:09:51,750 --> 00:09:56,909
red pixels here and no red pixels here

253
00:09:54,269 --> 00:09:58,318
so we can very easily directly quantify

254
00:09:56,909 --> 00:10:00,120
from the sensor measurements directly

255
00:09:58,318 --> 00:10:03,750
from the sensor measurements we can

256
00:10:00,120 --> 00:10:06,690
quantify what's the redness of that

257
00:10:03,750 --> 00:10:08,610
flower okay so that gets us to traits

258
00:10:06,690 --> 00:10:10,110
like you know how green is the plant but

259
00:10:08,610 --> 00:10:12,120
we really want to get to more what I

260
00:10:10,110 --> 00:10:14,459
like complex traits not in genetic

261
00:10:12,120 --> 00:10:17,159
architecture but just in like the actual

262
00:10:14,458 --> 00:10:18,809
physical architecture of those traits so

263
00:10:17,159 --> 00:10:23,759
if you wanted to phenotype actually for

264
00:10:18,809 --> 00:10:25,349
flower tight okay what this would look

265
00:10:23,759 --> 00:10:30,930
like is you actually have some really

266
00:10:25,350 --> 00:10:32,850
complicated function on here that the

267
00:10:30,929 --> 00:10:35,758
you can look at this and say you know

268
00:10:32,850 --> 00:10:37,050
this is a lily this is a petunia but

269
00:10:35,759 --> 00:10:39,060
with that you're taking a lot of

270
00:10:37,049 --> 00:10:40,620
background knowledge of like what the

271
00:10:39,059 --> 00:10:42,568
shape of the flower looks like what

272
00:10:40,620 --> 00:10:46,318
different colors those flowers come in

273
00:10:42,568 --> 00:10:47,698
you know you know the one time your

274
00:10:46,318 --> 00:10:50,370
significant other gave you some flowers

275
00:10:47,698 --> 00:10:52,289
and they were petunias or lilies or your

276
00:10:50,370 --> 00:10:54,089
favorite whatever it's this some really

277
00:10:52,289 --> 00:10:56,129
complicated function to say like what

278
00:10:54,089 --> 00:10:58,290
type of flower this is takes into

279
00:10:56,129 --> 00:11:00,179
account the shape and everything so this

280
00:10:58,289 --> 00:11:02,250
is this is where we get into like this

281
00:11:00,179 --> 00:11:06,409
deep learning of wanting to be able to

282
00:11:02,250 --> 00:11:11,458
apply this directly on images to score

283
00:11:06,409 --> 00:11:13,110
complex traits and heat so this is like

284
00:11:11,458 --> 00:11:14,969
the this is the real simple background

285
00:11:13,110 --> 00:11:18,360
and here again we got like fabulous

286
00:11:14,970 --> 00:11:22,079
computer science collaborators so I'll

287
00:11:18,360 --> 00:11:23,519
give you my cursory overview and I'm not

288
00:11:22,078 --> 00:11:26,188
reassure anybody really understands how

289
00:11:23,519 --> 00:11:27,870
these work anyway so we'll just tell you

290
00:11:26,188 --> 00:11:29,278
what we know about so these are

291
00:11:27,870 --> 00:11:31,799
convolutional neural networks you start

292
00:11:29,278 --> 00:11:33,179
with some two-dimensional representation

293
00:11:31,799 --> 00:11:35,149
so this has to be like an image that

294
00:11:33,179 --> 00:11:37,409
actually has like some spatial

295
00:11:35,149 --> 00:11:38,669
representation of something and then

296
00:11:37,409 --> 00:11:43,000
they're put through these convolutions

297
00:11:38,669 --> 00:11:45,969
until you actually get linear mapping of

298
00:11:43,000 --> 00:11:47,529
pixels into some function okay so if the

299
00:11:45,970 --> 00:11:48,970
relationship we want is sufficiently

300
00:11:47,529 --> 00:11:51,549
complicating meaning it's like some

301
00:11:48,970 --> 00:11:53,170
plant morphology there's not really a

302
00:11:51,549 --> 00:11:56,769
linear function that map's the input

303
00:11:53,169 --> 00:11:58,149
data this this image into like an output

304
00:11:56,769 --> 00:12:01,360
data that we want to put them in like

305
00:11:58,149 --> 00:12:03,009
two classes okay so we can use these

306
00:12:01,360 --> 00:12:05,259
deep learning it goes through these

307
00:12:03,009 --> 00:12:07,090
complicated functions sequence simpler

308
00:12:05,259 --> 00:12:08,080
functions that did the network learns

309
00:12:07,090 --> 00:12:09,990
all at once so these are the

310
00:12:08,080 --> 00:12:12,009
convolutional layers it takes it to be

311
00:12:09,990 --> 00:12:14,649
convolutions over the map of input

312
00:12:12,009 --> 00:12:16,299
values okay but the important part is

313
00:12:14,649 --> 00:12:18,039
that some notion of spatial structure so

314
00:12:16,299 --> 00:12:22,120
just like we look at it image has some

315
00:12:18,039 --> 00:12:25,149
spatial structure okay so what do we

316
00:12:22,120 --> 00:12:26,560
need so they real the real catch for

317
00:12:25,149 --> 00:12:28,149
doing any of these deep learning

318
00:12:26,559 --> 00:12:30,699
projects you have to have it's huge data

319
00:12:28,149 --> 00:12:32,259
set before you can even start right so

320
00:12:30,700 --> 00:12:33,670
this is like the catch-22 you don't know

321
00:12:32,259 --> 00:12:36,850
if it's going to work until like you've

322
00:12:33,669 --> 00:12:39,939
after you've done the entire experiment

323
00:12:36,850 --> 00:12:42,100
right okay so you know you said we've

324
00:12:39,940 --> 00:12:44,050
got data sets now that are actually

325
00:12:42,100 --> 00:12:46,389
hundreds of thousands of images showing

326
00:12:44,049 --> 00:12:47,620
this next slide or coming up it like on

327
00:12:46,389 --> 00:12:49,360
that same phenotype where we actually

328
00:12:47,620 --> 00:12:50,679
mounted multiple cameras and you can

329
00:12:49,360 --> 00:12:53,080
drive through the field and take images

330
00:12:50,679 --> 00:12:56,529
of the field so we did this over two

331
00:12:53,080 --> 00:12:58,240
years 2016-2017 we have the same GPS so

332
00:12:56,529 --> 00:13:00,250
we can we can assign those images to

333
00:12:58,240 --> 00:13:01,839
individual field plots so we know every

334
00:13:00,250 --> 00:13:03,669
field plot that each image was taken

335
00:13:01,839 --> 00:13:05,770
from and then we can go out and score

336
00:13:03,669 --> 00:13:08,049
for traits of interest right and then

337
00:13:05,769 --> 00:13:10,750
assign those scores to the images that

338
00:13:08,049 --> 00:13:12,509
were taken on that day from that plot

339
00:13:10,750 --> 00:13:15,940
okay so this way we call them breeder

340
00:13:12,509 --> 00:13:17,649
train data sets okay and then we can use

341
00:13:15,940 --> 00:13:19,600
like some way to classification we can

342
00:13:17,649 --> 00:13:22,230
classify them as percentages or we can

343
00:13:19,600 --> 00:13:24,399
classify the images into some categories

344
00:13:22,230 --> 00:13:26,680
is how this ways work and then we

345
00:13:24,399 --> 00:13:30,069
penalize them by how far the way the

346
00:13:26,679 --> 00:13:33,429
labels are like the labels that we gave

347
00:13:30,070 --> 00:13:35,320
them to that the network gave them to

348
00:13:33,429 --> 00:13:38,019
the to the ground truth right meaning

349
00:13:35,320 --> 00:13:40,070
like the labels that we visually scored

350
00:13:38,019 --> 00:13:42,919
the field plots

351
00:13:40,070 --> 00:13:44,180
ok so that's the idea so so the real

352
00:13:42,919 --> 00:13:46,639
catch it likes if you didn't catch that

353
00:13:44,179 --> 00:13:47,870
the real catch here is that before you

354
00:13:46,639 --> 00:13:49,639
know if this experiments going to work

355
00:13:47,870 --> 00:13:51,379
you've actually invested like multiple

356
00:13:49,639 --> 00:13:54,860
years of graduate students and postdocs

357
00:13:51,379 --> 00:13:56,779
and and just to get the data set to see

358
00:13:54,860 --> 00:13:57,710
if if you can train these neural

359
00:13:56,779 --> 00:13:59,480
networks ok

360
00:13:57,710 --> 00:14:01,400
so here's some of our field trials that

361
00:13:59,480 --> 00:14:04,940
we've been doing this these are just one

362
00:14:01,399 --> 00:14:06,529
of our research farms close to Kansas

363
00:14:04,940 --> 00:14:08,300
State we did this in two years

364
00:14:06,529 --> 00:14:10,250
most of our imaging these are winter

365
00:14:08,299 --> 00:14:12,469
weeds so we plant them in October we

366
00:14:10,250 --> 00:14:14,840
harvest them in June you know we we

367
00:14:12,470 --> 00:14:16,700
image them through heading development

368
00:14:14,840 --> 00:14:18,560
and through grain filling so that's an

369
00:14:16,700 --> 00:14:21,110
April in May we have about two months

370
00:14:18,559 --> 00:14:22,789
there way we do phenotyping and then the

371
00:14:21,110 --> 00:14:26,000
germ plasm we did this on we had an

372
00:14:22,789 --> 00:14:27,559
association panel this is 300 some lines

373
00:14:26,000 --> 00:14:28,789
this is just winter wheat varieties

374
00:14:27,559 --> 00:14:31,129
these are well-adapted these are all

375
00:14:28,789 --> 00:14:33,860
elite type materials we don't have any

376
00:14:31,129 --> 00:14:35,809
wild looking material in any of these

377
00:14:33,860 --> 00:14:37,730
things and so these are winter wheat

378
00:14:35,809 --> 00:14:40,609
varieties important to know and about 5%

379
00:14:37,730 --> 00:14:42,200
of these were honest types so if you're

380
00:14:40,610 --> 00:14:45,350
not familiar with wheat morphology you

381
00:14:42,200 --> 00:14:46,940
can have on which are the little spikes

382
00:14:45,350 --> 00:14:50,930
that come out of look we eat or you can

383
00:14:46,940 --> 00:14:53,300
have on list which is like a naked type

384
00:14:50,929 --> 00:14:55,870
type we head and then we had a

385
00:14:53,299 --> 00:14:58,039
recombinant in Red Line population

386
00:14:55,870 --> 00:15:01,360
Lincoln fivefold these are two varieties

387
00:14:58,039 --> 00:15:04,669
so this is a pretty elite well adapt in

388
00:15:01,360 --> 00:15:06,080
instead of germ plasm okay so here's

389
00:15:04,669 --> 00:15:08,120
what our phenotype er looks like from an

390
00:15:06,080 --> 00:15:09,680
aerial picture we've got like a little

391
00:15:08,120 --> 00:15:11,210
canopy over there to make a little bit

392
00:15:09,679 --> 00:15:13,159
of shading it makes the imaging a little

393
00:15:11,210 --> 00:15:15,590
more uniform same thing you can see the

394
00:15:13,159 --> 00:15:19,009
GPS units on top of that thing so each

395
00:15:15,590 --> 00:15:21,170
image has a Geo position within within a

396
00:15:19,009 --> 00:15:22,610
plot and then we have a some camera

397
00:15:21,169 --> 00:15:26,059
setup where we have different cameras

398
00:15:22,610 --> 00:15:27,889
just passing about less than half a

399
00:15:26,059 --> 00:15:32,899
meter over the field plot and then

400
00:15:27,889 --> 00:15:35,090
taking taking a really proximal image of

401
00:15:32,899 --> 00:15:36,439
those fuel plots and so this is this is

402
00:15:35,090 --> 00:15:38,720
kind of what that data collection looks

403
00:15:36,440 --> 00:15:40,850
like and and not to underestimate you

404
00:15:38,720 --> 00:15:42,830
know the amount of time and complexity

405
00:15:40,850 --> 00:15:44,680
that went into like just getting the

406
00:15:42,830 --> 00:15:46,310
datasets

407
00:15:44,679 --> 00:15:48,500
so here's

408
00:15:46,309 --> 00:15:49,879
like I said complex trait in who eat

409
00:15:48,500 --> 00:15:52,070
it's not actually complex because it's

410
00:15:49,879 --> 00:15:54,259
like a single gene controlled trait but

411
00:15:52,070 --> 00:15:56,420
it's complex in the sense of like the

412
00:15:54,259 --> 00:15:58,370
morphology okay so here's a picture of

413
00:15:56,419 --> 00:16:01,240
some onlus types you see that there's no

414
00:15:58,370 --> 00:16:03,589
beards on here and you see these long

415
00:16:01,240 --> 00:16:05,960
beards coming out of the wheat head here

416
00:16:03,589 --> 00:16:08,779
right so we have a few thousand pictures

417
00:16:05,960 --> 00:16:11,720
that are on this and you know more that

418
00:16:08,778 --> 00:16:14,389
are on here so this is the kind of this

419
00:16:11,720 --> 00:16:15,830
is what the training data set looks like

420
00:16:14,389 --> 00:16:18,080
you know we have thousands and thousands

421
00:16:15,830 --> 00:16:21,620
of pictures that look like these two

422
00:16:18,080 --> 00:16:22,580
sets here so we make this thing we call

423
00:16:21,620 --> 00:16:25,700
it wheat net

424
00:16:22,580 --> 00:16:27,110
I guess now so this is for scoring on so

425
00:16:25,700 --> 00:16:30,170
we started out with this is a really

426
00:16:27,110 --> 00:16:32,778
simple trait in the sense of it's just

427
00:16:30,169 --> 00:16:35,778
got two classes and we can say yes or no

428
00:16:32,778 --> 00:16:37,970
it's on or on this okay so we have about

429
00:16:35,778 --> 00:16:41,509
700 plots this was two replications of

430
00:16:37,970 --> 00:16:43,970
those 300 entries 29 of those are on

431
00:16:41,509 --> 00:16:47,210
this okay so we must had one plot die

432
00:16:43,970 --> 00:16:48,830
out it should've been 30 but so then we

433
00:16:47,210 --> 00:16:50,540
separate these into a training and a

434
00:16:48,830 --> 00:16:52,070
validation in the testing set remember

435
00:16:50,539 --> 00:16:53,360
we did this across two years so we

436
00:16:52,070 --> 00:16:55,250
trained it on one year and then we

437
00:16:53,360 --> 00:16:58,639
validated a totally separate field

438
00:16:55,250 --> 00:17:00,740
experiment from the other year so we

439
00:16:58,639 --> 00:17:02,449
trained it so what we do is we pick out

440
00:17:00,740 --> 00:17:04,429
several thousand images that are on

441
00:17:02,450 --> 00:17:07,250
several thousand equal number of images

442
00:17:04,429 --> 00:17:10,130
that are on this and then you train

443
00:17:07,250 --> 00:17:11,420
these accordingly so then you validate

444
00:17:10,130 --> 00:17:14,630
them so the important part is you train

445
00:17:11,420 --> 00:17:16,939
it you tune them you tune the model to

446
00:17:14,630 --> 00:17:19,010
optimize on the validation set and then

447
00:17:16,939 --> 00:17:20,959
to be fair you have to do the testing on

448
00:17:19,009 --> 00:17:22,838
a totally independent data set that

449
00:17:20,959 --> 00:17:26,089
didn't go into any way into your model

450
00:17:22,838 --> 00:17:28,250
building okay so this is what these guys

451
00:17:26,088 --> 00:17:30,678
are computer science guys call these a

452
00:17:28,250 --> 00:17:33,140
confusion matrix I don't really know why

453
00:17:30,679 --> 00:17:35,269
but anyway this is the this is basically

454
00:17:33,140 --> 00:17:38,060
the proportion you know here in it's

455
00:17:35,269 --> 00:17:39,950
like a heat map here in in the white is

456
00:17:38,059 --> 00:17:42,589
like is

457
00:17:39,950 --> 00:17:45,140
is one to one so that the here's the

458
00:17:42,589 --> 00:17:47,240
observed and here's the predicted right

459
00:17:45,140 --> 00:17:51,590
so we hit like extremely high accuracy

460
00:17:47,240 --> 00:17:54,650
99 plus percent accuracy on the training

461
00:17:51,589 --> 00:17:58,189
set the validation set and the testing

462
00:17:54,650 --> 00:18:01,610
set okay so what that looked like then

463
00:17:58,190 --> 00:18:04,789
in in the image numbers there is is is

464
00:18:01,609 --> 00:18:08,949
is is because these images can only be

465
00:18:04,789 --> 00:18:11,629
fed into the network in small 250 by 250

466
00:18:08,950 --> 00:18:14,539
sized images you can't take like an 18

467
00:18:11,630 --> 00:18:16,760
megapixel image just computationally so

468
00:18:14,539 --> 00:18:18,529
it's 250 by 250 so we actually have 10

469
00:18:16,759 --> 00:18:20,599
image crops that come out of each image

470
00:18:18,529 --> 00:18:23,029
and so that's the accuracy on those

471
00:18:20,599 --> 00:18:24,649
image that they cropped out images and

472
00:18:23,029 --> 00:18:27,139
then when we take a consensus from all

473
00:18:24,650 --> 00:18:29,780
of the crops that come up from a single

474
00:18:27,140 --> 00:18:32,090
image then we actually hit up to 100%

475
00:18:29,779 --> 00:18:34,819
accuracy and then remember also that we

476
00:18:32,089 --> 00:18:37,819
have multiple images from each plot and

477
00:18:34,819 --> 00:18:40,759
so on a plot level base this weekend we

478
00:18:37,819 --> 00:18:44,569
can hit 100% accuracy for scoring on vs.

479
00:18:40,759 --> 00:18:46,700
on us okay so like that's pretty awesome

480
00:18:44,569 --> 00:18:48,429
but you know you could walk through the

481
00:18:46,700 --> 00:18:52,250
field in 30 minutes and score this also

482
00:18:48,430 --> 00:18:55,700
so so we spent three years building a

483
00:18:52,250 --> 00:18:58,430
phenotype err and you know full-time

484
00:18:55,700 --> 00:19:02,380
postdoc and a computer graduate student

485
00:18:58,430 --> 00:19:05,870
and you know several million CPU hours

486
00:19:02,380 --> 00:19:07,730
but we can score on vs. on this ok so

487
00:19:05,869 --> 00:19:09,229
now let's go to something a little more

488
00:19:07,730 --> 00:19:11,180
interesting a little more complex this

489
00:19:09,230 --> 00:19:12,410
is growth stages and wheat that's you

490
00:19:11,180 --> 00:19:14,840
have to trust me that's what it says up

491
00:19:12,410 --> 00:19:16,340
there and so if you look at wheat

492
00:19:14,839 --> 00:19:17,929
development here you go through these

493
00:19:16,339 --> 00:19:22,339
stages where we're in tillering stage

494
00:19:17,930 --> 00:19:24,410
here then you're in stem elongation here

495
00:19:22,339 --> 00:19:26,029
these nodes are coming out here and then

496
00:19:24,410 --> 00:19:27,740
this is the important stage right here

497
00:19:26,029 --> 00:19:30,529
where the head is coming out of the boot

498
00:19:27,740 --> 00:19:32,660
so you know in a wheat grass the head

499
00:19:30,529 --> 00:19:34,670
emerges out of the boot from that from

500
00:19:32,660 --> 00:19:37,190
that flag leaf and this is real critical

501
00:19:34,670 --> 00:19:38,960
stage obviously right that's when that's

502
00:19:37,190 --> 00:19:41,750
when flowering is happening that

503
00:19:38,960 --> 00:19:44,509
determines the overall morphology the

504
00:19:41,750 --> 00:19:45,980
the timing of that flowering so and then

505
00:19:44,509 --> 00:19:47,960
this is the critical grain filling

506
00:19:45,980 --> 00:19:49,789
period so these are traditionally scored

507
00:19:47,960 --> 00:19:51,100
as when 50% of the tillers have headed

508
00:19:49,789 --> 00:19:53,528
on the boot so

509
00:19:51,099 --> 00:19:55,058
you know like so visually this is really

510
00:19:53,528 --> 00:19:57,308
easy to score you just look at the plot

511
00:19:55,058 --> 00:19:59,048
you take a mental assessment of how many

512
00:19:57,308 --> 00:20:00,759
tillers are out there and then you take

513
00:19:59,048 --> 00:20:04,269
a mental assessment of how many of those

514
00:20:00,759 --> 00:20:05,470
are 50% out okay but actually like when

515
00:20:04,269 --> 00:20:08,109
you think about what actually just

516
00:20:05,470 --> 00:20:09,788
happened in a split second in your own

517
00:20:08,109 --> 00:20:11,709
neural network that's like actually

518
00:20:09,788 --> 00:20:13,599
extremely complicated because you had to

519
00:20:11,710 --> 00:20:14,980
take some visual assessment not just of

520
00:20:13,599 --> 00:20:17,589
like how many are out but of like the

521
00:20:14,980 --> 00:20:19,630
total density of those also okay

522
00:20:17,589 --> 00:20:21,579
obviously it's a really important

523
00:20:19,630 --> 00:20:23,590
physiological trait so like for example

524
00:20:21,579 --> 00:20:25,210
in Kansas you can't be too early or

525
00:20:23,589 --> 00:20:26,589
you'll get winter kill and you don't

526
00:20:25,210 --> 00:20:28,120
want to be too late because then you'll

527
00:20:26,589 --> 00:20:30,428
be into the heat stress of the hot

528
00:20:28,119 --> 00:20:34,000
summers okay so this is really critical

529
00:20:30,429 --> 00:20:35,980
breeder selection and so why was this

530
00:20:34,000 --> 00:20:38,019
something we want to go after for http/1

531
00:20:35,980 --> 00:20:39,278
is like a time series measurement so

532
00:20:38,019 --> 00:20:40,870
it's recorded as a date so you actually

533
00:20:39,278 --> 00:20:43,569
have to go out multiple time points

534
00:20:40,869 --> 00:20:45,518
during the season to accurately measure

535
00:20:43,569 --> 00:20:48,308
this right so it requires going through

536
00:20:45,519 --> 00:20:51,690
all the plots each day or at least every

537
00:20:48,308 --> 00:20:51,690
other day something like that

538
00:20:53,869 --> 00:20:57,869
okay so here's what here's what some of

539
00:20:56,490 --> 00:21:00,630
our image sets look like so we actually

540
00:20:57,869 --> 00:21:02,819
do this now in time series okay so if

541
00:21:00,630 --> 00:21:04,650
you take a plot early on it'll be all

542
00:21:02,819 --> 00:21:06,418
leafy like this you don't see any heads

543
00:21:04,650 --> 00:21:08,759
out you see one here just starting to

544
00:21:06,419 --> 00:21:11,100
come out of the boot right so this might

545
00:21:08,759 --> 00:21:13,859
be like you know somewhere between 1 to

546
00:21:11,099 --> 00:21:14,879
5 percent headed right and here's

547
00:21:13,859 --> 00:21:17,759
another one that's almost completely

548
00:21:14,880 --> 00:21:19,169
headed out so it's a little dark to see

549
00:21:17,759 --> 00:21:21,210
maybe from the back but you can see that

550
00:21:19,169 --> 00:21:23,669
all the heads are out here now you might

551
00:21:21,210 --> 00:21:26,910
have one or two real late ones this is

552
00:21:23,669 --> 00:21:29,790
about 90% headed out here so what we do

553
00:21:26,910 --> 00:21:31,440
now is we go through the field each day

554
00:21:29,789 --> 00:21:33,418
we take a visual score or we run the

555
00:21:31,440 --> 00:21:35,850
phenotype at the same time and then we

556
00:21:33,419 --> 00:21:37,830
can we can take 10,000 images in a day

557
00:21:35,849 --> 00:21:40,369
and by going through the field once we

558
00:21:37,829 --> 00:21:42,449
can assign a value to every one of those

559
00:21:40,369 --> 00:21:43,979
10,000 images and then we do that at

560
00:21:42,450 --> 00:21:46,080
multiple time points through the season

561
00:21:43,980 --> 00:21:48,599
so then you get an eye photos library

562
00:21:46,079 --> 00:21:50,428
that looks something like this where you

563
00:21:48,599 --> 00:21:52,529
you know you filled up your library with

564
00:21:50,429 --> 00:21:55,169
hundred thousand pictures and every one

565
00:21:52,529 --> 00:21:57,509
of them's like 10% headed or 90% headed

566
00:21:55,169 --> 00:21:59,880
or 60% something like this

567
00:21:57,509 --> 00:22:02,849
and so we have a huge training data set

568
00:21:59,880 --> 00:22:04,730
now where we have all of these images

569
00:22:02,849 --> 00:22:08,548
and they're tagged is like a breeder

570
00:22:04,730 --> 00:22:10,858
trained type of score

571
00:22:08,548 --> 00:22:11,759
so this is training wheat net for

572
00:22:10,858 --> 00:22:14,009
heading here

573
00:22:11,759 --> 00:22:15,058
I saw our training sets so here's where

574
00:22:14,009 --> 00:22:17,009
we go back and we have two different

575
00:22:15,058 --> 00:22:18,749
populations so we have one populations

576
00:22:17,009 --> 00:22:21,538
diversity panel it's got a much bigger

577
00:22:18,749 --> 00:22:23,579
morphology and then we applied this to

578
00:22:21,538 --> 00:22:26,398
the buy print of population it's much

579
00:22:23,579 --> 00:22:28,439
more narrow in its morphology okay so

580
00:22:26,398 --> 00:22:30,658
the training set here we had this Lake

581
00:22:28,440 --> 00:22:32,459
at Fuller by parental population in 2016

582
00:22:30,659 --> 00:22:36,179
we had two years of the Association

583
00:22:32,459 --> 00:22:37,889
panel and then we balance this out with

584
00:22:36,179 --> 00:22:40,288
about two thousand images per maturity

585
00:22:37,888 --> 00:22:42,748
level so so in ten ten percent

586
00:22:40,288 --> 00:22:45,509
increments from 0 to 100 and so that was

587
00:22:42,749 --> 00:22:48,479
a total around 20 thousand training

588
00:22:45,509 --> 00:22:50,278
images and two hundred thousand patches

589
00:22:48,479 --> 00:22:52,048
from those images so each one of those

590
00:22:50,278 --> 00:22:55,828
patches actually counts as like an

591
00:22:52,048 --> 00:22:57,509
individual training data point okay it's

592
00:22:55,828 --> 00:22:58,979
in the validation set was the same thing

593
00:22:57,509 --> 00:23:00,989
a hundred pots from this diversity panel

594
00:22:58,979 --> 00:23:03,749
and this is the part that I don't really

595
00:23:00,989 --> 00:23:06,569
know but if you're deep into neural

596
00:23:03,749 --> 00:23:09,179
networks then then here's all the gory

597
00:23:06,569 --> 00:23:11,338
details on this so you have to because

598
00:23:09,179 --> 00:23:13,109
because of memory memory limitations you

599
00:23:11,338 --> 00:23:14,969
have to feed these inner and small

600
00:23:13,108 --> 00:23:17,489
batches so you can't actually you can't

601
00:23:14,969 --> 00:23:19,919
actually put like 200,000 images and at

602
00:23:17,489 --> 00:23:22,528
the same time and then we didn't have to

603
00:23:19,919 --> 00:23:24,419
tune the parameters for how how fast the

604
00:23:22,528 --> 00:23:26,909
is the learning rate and then how many

605
00:23:24,419 --> 00:23:29,159
epics it's trained and then the total

606
00:23:26,909 --> 00:23:31,169
number of training there so this was all

607
00:23:29,159 --> 00:23:33,719
optimized and it turns out interesting

608
00:23:31,169 --> 00:23:35,549
that the really crazy part to me is that

609
00:23:33,719 --> 00:23:37,288
these networks are pre-trained unlike

610
00:23:35,548 --> 00:23:39,778
just random images from the internet and

611
00:23:37,288 --> 00:23:43,798
then we just train the last few layers

612
00:23:39,778 --> 00:23:46,048
on the wheat data and then interestingly

613
00:23:43,798 --> 00:23:49,019
like these networks that we train for

614
00:23:46,048 --> 00:23:51,628
like the on versus on this versus the

615
00:23:49,019 --> 00:23:53,368
percentage heading they it was like only

616
00:23:51,628 --> 00:23:57,349
like the last one or two layers that

617
00:23:53,368 --> 00:23:59,699
were trained differently okay

618
00:23:57,349 --> 00:24:01,918
so what this looked like then in the

619
00:23:59,700 --> 00:24:03,509
field is that if we go out over time

620
00:24:01,919 --> 00:24:06,059
series so say right here we have plot

621
00:24:03,509 --> 00:24:08,579
number one plot number two down to plot

622
00:24:06,058 --> 00:24:11,069
number in if we go through the field and

623
00:24:08,579 --> 00:24:13,138
we image those day by day and we also

624
00:24:11,069 --> 00:24:16,230
take a visual score then we have a time

625
00:24:13,138 --> 00:24:19,618
series imaging where we can assign an

626
00:24:16,230 --> 00:24:21,239
image value and a percentage scoring to

627
00:24:19,618 --> 00:24:23,699
that right so we can train the neural

628
00:24:21,239 --> 00:24:24,989
network on these and then to do this at

629
00:24:23,700 --> 00:24:28,259
high throughput we can just go measure

630
00:24:24,989 --> 00:24:29,759
new plots and just have the images and

631
00:24:28,259 --> 00:24:31,710
then using the neural network we can

632
00:24:29,759 --> 00:24:34,169
actually assign the percentages to each

633
00:24:31,710 --> 00:24:35,730
day right and then we just need to find

634
00:24:34,169 --> 00:24:39,419
the intersection of when it goes above

635
00:24:35,730 --> 00:24:45,149
50% and that would be the classical

636
00:24:39,419 --> 00:24:47,460
measure okay so this is what it looks

637
00:24:45,148 --> 00:24:49,439
like then so we do a time series imaging

638
00:24:47,460 --> 00:24:52,079
and then we fit this percent heading

639
00:24:49,440 --> 00:24:55,249
model here where we fit a logistic

640
00:24:52,079 --> 00:24:57,418
regression onto those time series

641
00:24:55,249 --> 00:24:58,980
measurements and so this is what some

642
00:24:57,419 --> 00:25:00,809
real data looks like these are actually

643
00:24:58,980 --> 00:25:02,368
visual scores and then I'll show you the

644
00:25:00,808 --> 00:25:05,608
neural network scores in a minute here

645
00:25:02,368 --> 00:25:08,069
so this would be a field plot this is

646
00:25:05,608 --> 00:25:11,189
our plot identify our plot number two

647
00:25:08,069 --> 00:25:14,638
zero zero one four where it was scored

648
00:25:11,190 --> 00:25:16,679
on on day one 10 a zero the next time

649
00:25:14,638 --> 00:25:19,138
point it would have been scored at 20 40

650
00:25:16,679 --> 00:25:21,330
50 80 and then the rest of the time

651
00:25:19,138 --> 00:25:23,819
points were scored at one honey so we

652
00:25:21,329 --> 00:25:25,980
fit this logistic regression on here

653
00:25:23,819 --> 00:25:29,730
this is just a classical resistant

654
00:25:25,980 --> 00:25:34,679
logistic regression equation we take and

655
00:25:29,730 --> 00:25:36,118
we fix Phi one here at 100% so that you

656
00:25:34,679 --> 00:25:40,169
know all the wheat plots have to end up

657
00:25:36,118 --> 00:25:42,089
at 100% headed out we actually put some

658
00:25:40,169 --> 00:25:43,769
dummy variables at 0 and 100 which

659
00:25:42,089 --> 00:25:45,720
passed our measurement day is just to

660
00:25:43,769 --> 00:25:48,358
help fit the regression and then Phi 2

661
00:25:45,720 --> 00:25:50,548
and Phi 3 here are actually the slope

662
00:25:48,358 --> 00:25:53,339
and and then the intercept you know way

663
00:25:50,548 --> 00:25:56,940
down here this the slope of that of that

664
00:25:53,339 --> 00:25:58,738
curve here so we fixed by 1 by 100 we

665
00:25:56,940 --> 00:26:01,980
find then we just simply find the date

666
00:25:58,739 --> 00:26:04,920
at with which that which that logistic

667
00:26:01,980 --> 00:26:07,440
regression intersects the 50%

668
00:26:04,920 --> 00:26:09,360
right so we find 50% here we find that

669
00:26:07,440 --> 00:26:13,620
date and then you know this one is

670
00:26:09,359 --> 00:26:16,439
around J 1:18 we we assign that as the

671
00:26:13,619 --> 00:26:18,239
heading date the cool thing here that

672
00:26:16,440 --> 00:26:20,309
I'll come back to is that because we

673
00:26:18,240 --> 00:26:22,170
have the slope of how quickly it goes

674
00:26:20,309 --> 00:26:25,829
from 0 to 100 we can actually measure

675
00:26:22,170 --> 00:26:27,180
the rate of heading K and so this would

676
00:26:25,829 --> 00:26:28,889
be a really interesting trait that you

677
00:26:27,180 --> 00:26:31,140
might think about you know in some cases

678
00:26:28,890 --> 00:26:34,200
you weren't really rapid heading so that

679
00:26:31,140 --> 00:26:36,360
everything uniformly heads at the same

680
00:26:34,200 --> 00:26:38,069
time if you're in like a risky

681
00:26:36,359 --> 00:26:40,529
environment where you might like get

682
00:26:38,069 --> 00:26:42,809
late freeze or early early stress you

683
00:26:40,529 --> 00:26:44,819
might want to stretch out a heading date

684
00:26:42,809 --> 00:26:45,779
so this is a cool new breeding target

685
00:26:44,819 --> 00:26:48,359
that we've been thinking about now that

686
00:26:45,779 --> 00:26:52,619
you can actually like measure and then

687
00:26:48,359 --> 00:26:56,009
presumably breed for the rate of heading

688
00:26:52,619 --> 00:26:57,599
and so what we do then is we is we do

689
00:26:56,009 --> 00:26:59,549
that exact same thing with a neural

690
00:26:57,599 --> 00:27:01,949
network and so remember now the visual

691
00:26:59,549 --> 00:27:03,720
scores are we go out here and we take

692
00:27:01,950 --> 00:27:05,970
visual measurements the neural network

693
00:27:03,720 --> 00:27:07,799
here is we actually image the plots we

694
00:27:05,970 --> 00:27:09,420
train the neural networking we assign a

695
00:27:07,799 --> 00:27:12,210
value for the image on each one of those

696
00:27:09,420 --> 00:27:14,759
days so the purple dots here are scores

697
00:27:12,210 --> 00:27:16,860
from the neural network based on imaging

698
00:27:14,759 --> 00:27:19,049
and then we fit that same logistic

699
00:27:16,859 --> 00:27:21,899
regression we find from the neural

700
00:27:19,049 --> 00:27:25,069
network scores right based on that

701
00:27:21,900 --> 00:27:28,100
logistic regression the heading date and

702
00:27:25,069 --> 00:27:31,950
and then we can basically

703
00:27:28,099 --> 00:27:34,889
fully-automated measure the progression

704
00:27:31,950 --> 00:27:37,200
of heading and then find the date in

705
00:27:34,890 --> 00:27:40,620
which it hits that classical measure of

706
00:27:37,200 --> 00:27:42,360
50% heading so this is this is overall

707
00:27:40,619 --> 00:27:44,939
how we do it right this is the example

708
00:27:42,359 --> 00:27:46,589
of that same plot of course I show you

709
00:27:44,940 --> 00:27:49,710
the best example where they like match

710
00:27:46,589 --> 00:27:50,970
up perfectly right so yeah some of them

711
00:27:49,710 --> 00:27:52,650
were really good here's another great

712
00:27:50,970 --> 00:27:54,750
example where we hit you know basically

713
00:27:52,650 --> 00:27:56,310
hit it right on the same day some of

714
00:27:54,750 --> 00:27:59,339
them are not so good you know you have

715
00:27:56,309 --> 00:28:01,019
some overestimation in the neural

716
00:27:59,339 --> 00:28:03,750
network here from what the visual scores

717
00:28:01,019 --> 00:28:05,639
were at and so that slope kind of gets

718
00:28:03,750 --> 00:28:07,849
panned out and then you're then you miss

719
00:28:05,640 --> 00:28:09,259
it by about a day

720
00:28:07,849 --> 00:28:11,509
so basically now what we've done is

721
00:28:09,259 --> 00:28:13,250
we've high throughput measured through

722
00:28:11,509 --> 00:28:16,190
all of those plots we have a time series

723
00:28:13,250 --> 00:28:19,099
measurement about 10 10 or 11 time

724
00:28:16,190 --> 00:28:20,750
points where we've imaged dozens of

725
00:28:19,099 --> 00:28:22,579
images for each plot and then we just

726
00:28:20,750 --> 00:28:25,789
apply it individually this this

727
00:28:22,579 --> 00:28:27,619
regression across all of those plots so

728
00:28:25,789 --> 00:28:31,009
that's what this looks like then here so

729
00:28:27,619 --> 00:28:32,809
this would be the on this axis here is

730
00:28:31,009 --> 00:28:34,579
all of the time points that we took

731
00:28:32,809 --> 00:28:36,169
visual measurements you can see that

732
00:28:34,579 --> 00:28:38,419
those are nicely spaced out on Monday

733
00:28:36,170 --> 00:28:40,580
Wednesday and Friday across the growing

734
00:28:38,420 --> 00:28:42,830
season okay and so here's what we took

735
00:28:40,579 --> 00:28:45,289
visual visual measurements and then this

736
00:28:42,829 --> 00:28:47,659
would be that 50% estimate from the

737
00:28:45,289 --> 00:28:49,879
visual measurements on this axis here is

738
00:28:47,660 --> 00:28:51,680
that for each individual plot we fit

739
00:28:49,880 --> 00:28:54,650
that logistic regression based on the

740
00:28:51,680 --> 00:28:56,210
neural network scores and and then

741
00:28:54,650 --> 00:28:58,550
intersected that and got the same

742
00:28:56,210 --> 00:29:00,170
heading date for that and you can see

743
00:28:58,549 --> 00:29:02,720
here these are the time points you tried

744
00:29:00,170 --> 00:29:05,000
to do this every every other day so this

745
00:29:02,720 --> 00:29:07,220
you know this big gap here it's like one

746
00:29:05,000 --> 00:29:08,000
of the caveats of when it starts raining

747
00:29:07,220 --> 00:29:09,710
in the field

748
00:29:08,000 --> 00:29:11,569
you can't like drive your tractor

749
00:29:09,710 --> 00:29:13,130
through it anymore so we had it we had a

750
00:29:11,569 --> 00:29:16,609
pretty big gap in here where we weren't

751
00:29:13,130 --> 00:29:18,950
able to image the field and so overall

752
00:29:16,609 --> 00:29:21,039
though man we we had a big range and

753
00:29:18,950 --> 00:29:23,750
heading in this particular population

754
00:29:21,039 --> 00:29:24,950
but we had a really strong correlation

755
00:29:23,750 --> 00:29:28,579
you can see that here there's a nice

756
00:29:24,950 --> 00:29:30,110
one-to-one trend the the red line is the

757
00:29:28,579 --> 00:29:33,139
fit and then the black line is the

758
00:29:30,109 --> 00:29:35,149
one-to-one line on there and so we had a

759
00:29:33,140 --> 00:29:37,009
really strong correlation I'm a mean

760
00:29:35,150 --> 00:29:38,540
absolute error of less than one day and

761
00:29:37,009 --> 00:29:41,569
a root mean square error of just a day

762
00:29:38,539 --> 00:29:43,279
and a quarter so overall I think we get

763
00:29:41,569 --> 00:29:44,899
you know I think we're hitting within

764
00:29:43,279 --> 00:29:48,440
the tolerance of what you can actually

765
00:29:44,900 --> 00:29:49,840
visually score also we did have you can

766
00:29:48,440 --> 00:29:52,940
see kind of here we have a little bias

767
00:29:49,839 --> 00:29:55,549
right in this region I think I'm not

768
00:29:52,940 --> 00:29:57,110
real sure but my my working hypothesis

769
00:29:55,549 --> 00:29:58,639
is that that's because we had good

770
00:29:57,109 --> 00:30:01,429
imaging here and then we have this kind

771
00:29:58,640 --> 00:30:03,200
of gap in our imaging time points and so

772
00:30:01,430 --> 00:30:06,049
I think those curves got pushed up a

773
00:30:03,200 --> 00:30:09,590
little high and so we early we estimated

774
00:30:06,049 --> 00:30:11,769
the heading dates in this range a little

775
00:30:09,589 --> 00:30:15,439
a little earlier than they should have

776
00:30:11,769 --> 00:30:16,079
now but overall we can for compared to

777
00:30:15,440 --> 00:30:19,169
the visual

778
00:30:16,079 --> 00:30:21,089
with the neural network we can get 57%

779
00:30:19,169 --> 00:30:24,480
of the plots within one day of the

780
00:30:21,089 --> 00:30:27,028
visual estimate and we can get 88% of

781
00:30:24,480 --> 00:30:32,429
those within within two days of what

782
00:30:27,028 --> 00:30:35,190
they were visually scored so here's the

783
00:30:32,429 --> 00:30:36,750
distribution of those of the overall

784
00:30:35,190 --> 00:30:38,370
heading dates this is the day of the

785
00:30:36,750 --> 00:30:40,109
year where we estimated the heading date

786
00:30:38,369 --> 00:30:41,969
and this is the frequency for that

787
00:30:40,109 --> 00:30:43,949
population here's the Lincoln and fuller

788
00:30:41,970 --> 00:30:45,600
the parents of that of that by parental

789
00:30:43,950 --> 00:30:47,009
population and the difference between

790
00:30:45,599 --> 00:30:49,319
the visual and the neural network the

791
00:30:47,009 --> 00:30:51,839
visual here is in the dark and then the

792
00:30:49,319 --> 00:30:53,250
field the field background here and so

793
00:30:51,839 --> 00:30:55,558
you can see for the parents we were

794
00:30:53,250 --> 00:30:56,788
really accurate on those you can see

795
00:30:55,558 --> 00:30:59,819
that little shift in the distribution

796
00:30:56,788 --> 00:31:01,589
here between where we are in this you

797
00:30:59,819 --> 00:31:05,730
know in this one 15 day range we were

798
00:31:01,589 --> 00:31:07,709
about a day or two early on those but

799
00:31:05,730 --> 00:31:09,149
overall we can match the distribution we

800
00:31:07,710 --> 00:31:11,579
can get a really accurate assessment

801
00:31:09,148 --> 00:31:13,678
over there so if you're an astute

802
00:31:11,579 --> 00:31:15,240
graduate student now you're saying oh

803
00:31:13,679 --> 00:31:17,460
there's something really funky with this

804
00:31:15,240 --> 00:31:18,960
distribution that that doesn't look like

805
00:31:17,460 --> 00:31:21,808
a normal distribution okay we'll come

806
00:31:18,960 --> 00:31:22,860
back to that that's that's good okay so

807
00:31:21,808 --> 00:31:25,500
the other thing you can't see up here

808
00:31:22,859 --> 00:31:29,519
but this says 5/3 up there and so this

809
00:31:25,500 --> 00:31:32,190
is actually the slope of of those curves

810
00:31:29,519 --> 00:31:34,319
on there and so here's where I think we

811
00:31:32,190 --> 00:31:37,080
you know we had some some a little bit

812
00:31:34,319 --> 00:31:38,730
of bias with the neural network and the

813
00:31:37,079 --> 00:31:41,099
imaging set is where in this

814
00:31:38,730 --> 00:31:43,889
distribution here we're measuring the

815
00:31:41,099 --> 00:31:46,439
slope of heading you know the rate of

816
00:31:43,888 --> 00:31:50,278
heading using the neural network versus

817
00:31:46,440 --> 00:31:54,000
the rate of heading for for the visual

818
00:31:50,278 --> 00:31:55,919
scores and overall the you know the the

819
00:31:54,000 --> 00:31:58,950
slope of the curve estimated for the

820
00:31:55,919 --> 00:32:01,380
neural networks were steeper than for

821
00:31:58,950 --> 00:32:03,210
the visual scores and this this is in my

822
00:32:01,380 --> 00:32:08,200
mind I think this is due to just getting

823
00:32:03,210 --> 00:32:10,600
uniform timing of the imaging data sets

824
00:32:08,200 --> 00:32:14,379
okay overall I should say though to the

825
00:32:10,599 --> 00:32:15,398
heritability on the actual measurement

826
00:32:14,378 --> 00:32:19,988
of the heading day abroad since

827
00:32:15,398 --> 00:32:21,308
heritability was around 0.92 for the

828
00:32:19,989 --> 00:32:22,899
actual heading date and then

829
00:32:21,308 --> 00:32:24,638
surprisingly we had we had good

830
00:32:22,898 --> 00:32:29,979
heritability for both the visual and the

831
00:32:24,638 --> 00:32:31,658
neural network slope around 0.5 0.45 so

832
00:32:29,980 --> 00:32:34,480
I was surprised that we actually had

833
00:32:31,659 --> 00:32:36,879
heritable measures of of the rate of

834
00:32:34,480 --> 00:32:38,589
heading based on this approach so

835
00:32:36,878 --> 00:32:40,388
overall now we can like start to look at

836
00:32:38,589 --> 00:32:42,999
this in depth so here's just an example

837
00:32:40,388 --> 00:32:44,829
this is comparing the 5 3 so remember

838
00:32:42,999 --> 00:32:46,899
this is the slope this is the rate of

839
00:32:44,829 --> 00:32:49,449
heading compared to the heading date so

840
00:32:46,898 --> 00:32:50,918
you might say oh you know the the rate

841
00:32:49,450 --> 00:32:52,690
of heading is just determined by when

842
00:32:50,919 --> 00:32:53,710
you're actually heading but what we can

843
00:32:52,690 --> 00:32:55,359
see here is that there's a slight

844
00:32:53,710 --> 00:32:57,220
negative correlation but it's actually

845
00:32:55,358 --> 00:32:58,689
really weak so interestingly you can

846
00:32:57,220 --> 00:33:00,999
know you can pick stuff here that's like

847
00:32:58,690 --> 00:33:02,580
got a really rapid heading versus a

848
00:33:00,999 --> 00:33:05,558
really slow heading but they're actually

849
00:33:02,579 --> 00:33:07,628
end up heading at the 50% point they end

850
00:33:05,558 --> 00:33:09,128
up heading on the same day so this might

851
00:33:07,628 --> 00:33:10,778
be really interesting objectives if you

852
00:33:09,128 --> 00:33:12,538
ever wanted to like pick something

853
00:33:10,778 --> 00:33:17,618
that's early but it actually has a long

854
00:33:12,538 --> 00:33:19,450
duration of heading so we did just some

855
00:33:17,618 --> 00:33:21,849
simple genetic mapping we have we have

856
00:33:19,450 --> 00:33:23,649
GBS on this population about 14,000

857
00:33:21,849 --> 00:33:26,048
markers so we've tested this for days

858
00:33:23,648 --> 00:33:28,148
the heading and for that slope we just

859
00:33:26,048 --> 00:33:30,489
finished simple linear regression here

860
00:33:28,148 --> 00:33:35,709
where we're estimating the effect of

861
00:33:30,489 --> 00:33:37,778
each one of those markers so here's

862
00:33:35,710 --> 00:33:40,929
here's a classic Manhattan plot this is

863
00:33:37,778 --> 00:33:45,249
4 it says up here days - heading so this

864
00:33:40,929 --> 00:33:48,389
is the Association testing for days -

865
00:33:45,249 --> 00:33:50,440
heading here we got two really strong

866
00:33:48,388 --> 00:33:54,428
associations these are actually four

867
00:33:50,440 --> 00:33:55,869
known photo period sensitive alleles

868
00:33:54,429 --> 00:34:00,190
that are segregating in the breeding

869
00:33:55,868 --> 00:34:01,569
material so people do B 1 and D 1 so

870
00:34:00,190 --> 00:34:04,450
those are real nice associations here

871
00:34:01,569 --> 00:34:07,450
there's another Association strong that

872
00:34:04,450 --> 00:34:08,889
found on on one B we haven't quite

873
00:34:07,450 --> 00:34:11,740
figured out what that is and then maybe

874
00:34:08,889 --> 00:34:13,298
another one here on 3 B and then a few

875
00:34:11,739 --> 00:34:15,009
on the unanchored markers but these are

876
00:34:13,298 --> 00:34:17,648
actually turns out that there actually

877
00:34:15,010 --> 00:34:18,659
should be anchored on on to B so overall

878
00:34:17,648 --> 00:34:20,190
you can't really

879
00:34:18,659 --> 00:34:21,599
see it because they line directly up on

880
00:34:20,190 --> 00:34:23,429
top of each other but we did this for

881
00:34:21,599 --> 00:34:25,588
the visual assessments and the neural

882
00:34:23,429 --> 00:34:27,389
network and we can you can see a square

883
00:34:25,588 --> 00:34:29,849
right here in a circle right here so

884
00:34:27,389 --> 00:34:32,730
it's it's cool we can actually now map

885
00:34:29,849 --> 00:34:36,480
genetically map a trait that was fully

886
00:34:32,730 --> 00:34:39,539
scored using the automated imaging and

887
00:34:36,480 --> 00:34:41,369
the neural network so that's the

888
00:34:39,539 --> 00:34:43,889
Manhattan plot this is more of a

889
00:34:41,369 --> 00:34:48,059
Manhattan Kansas plot because it's a

890
00:34:43,889 --> 00:34:51,298
little flatter this is for 5/3 and and

891
00:34:48,059 --> 00:34:54,929
so same thing so even though we had a

892
00:34:51,298 --> 00:34:58,199
nice heritability trait point four we

893
00:34:54,929 --> 00:35:00,150
didn't find much for any genetic

894
00:34:58,199 --> 00:35:04,019
Association on those ones we maybe have

895
00:35:00,150 --> 00:35:06,298
something here onto B but we have to use

896
00:35:04,019 --> 00:35:08,219
genomic prediction models because there

897
00:35:06,298 --> 00:35:11,009
are apparently there's not any major

898
00:35:08,219 --> 00:35:12,500
control of even though it's heritable it

899
00:35:11,010 --> 00:35:17,789
doesn't look like there's any major

900
00:35:12,500 --> 00:35:21,510
major genetic control the rate of

901
00:35:17,789 --> 00:35:22,079
heading okay so this goes back to the

902
00:35:21,510 --> 00:35:23,400
question

903
00:35:22,079 --> 00:35:25,019
all those graduate students were

904
00:35:23,400 --> 00:35:27,000
wondering about it like like you get a

905
00:35:25,019 --> 00:35:29,068
unit distribution like this you got to

906
00:35:27,000 --> 00:35:30,989
say oh there's like some epistasis or

907
00:35:29,068 --> 00:35:34,858
something going on right if you can't

908
00:35:30,989 --> 00:35:36,179
explain it it's epistasis okay so so we

909
00:35:34,858 --> 00:35:37,588
took this we just fit a two-way

910
00:35:36,179 --> 00:35:39,568
interaction model for all the

911
00:35:37,588 --> 00:35:42,000
significant markers so right so it's

912
00:35:39,568 --> 00:35:44,759
marker one by mark or two and then the

913
00:35:42,000 --> 00:35:46,528
interaction of those two markers cool

914
00:35:44,760 --> 00:35:47,819
though if you take this distribution and

915
00:35:46,528 --> 00:35:51,150
you chop it off right here at the

916
00:35:47,818 --> 00:35:54,058
inflection point you run a chi-square of

917
00:35:51,150 --> 00:35:56,068
a three to one on that guy and it fits

918
00:35:54,059 --> 00:35:59,329
it fits really nicely with a three to

919
00:35:56,068 --> 00:36:03,150
one ratio which would be like a two gene

920
00:35:59,329 --> 00:36:05,460
dominance type epistatic model and so

921
00:36:03,150 --> 00:36:07,680
this is a nice working hypothesis we

922
00:36:05,460 --> 00:36:09,900
said ah yeah but there's some nice

923
00:36:07,679 --> 00:36:12,719
epistatic interactions between those two

924
00:36:09,900 --> 00:36:14,400
and so that's what I'm showing here this

925
00:36:12,719 --> 00:36:16,199
is just our first attempt to visualize

926
00:36:14,400 --> 00:36:20,068
this I'm not real sure but here's that

927
00:36:16,199 --> 00:36:23,189
same Association plot you know we had

928
00:36:20,068 --> 00:36:26,909
that strong peak on on to B and 2d for

929
00:36:23,190 --> 00:36:28,470
the for the 2p pd-1 alleles interesting

930
00:36:26,909 --> 00:36:31,170
like here's the allele effect so one of

931
00:36:28,469 --> 00:36:32,368
them was coming from parent one Lincoln

932
00:36:31,170 --> 00:36:35,159
and the other one was coming

933
00:36:32,369 --> 00:36:36,900
to folder right so they so individually

934
00:36:35,159 --> 00:36:39,179
as varieties they hit the right maturity

935
00:36:36,900 --> 00:36:41,369
right but their progeny get like thrown

936
00:36:39,179 --> 00:36:43,048
all over the place okay so so and I

937
00:36:41,369 --> 00:36:44,519
talked with Alan he said yeah for sure

938
00:36:43,048 --> 00:36:46,230
you know we can only have one of these

939
00:36:44,518 --> 00:36:48,838
in the prematurely if you put them both

940
00:36:46,230 --> 00:36:50,278
or too early you have neither one than

941
00:36:48,838 --> 00:36:52,528
they're way too late and sure enough

942
00:36:50,278 --> 00:36:53,880
right we got we got some these are just

943
00:36:52,528 --> 00:36:55,650
the size of these circles or the

944
00:36:53,880 --> 00:36:57,269
significance of interaction so this

945
00:36:55,650 --> 00:36:58,680
there's there's some interaction here

946
00:36:57,268 --> 00:37:00,179
with this this one allele but then

947
00:36:58,679 --> 00:37:03,659
there's really strong at interaction

948
00:37:00,179 --> 00:37:05,179
between the 2b and the 2d allele there

949
00:37:03,659 --> 00:37:07,980
so we have some classic kind of

950
00:37:05,179 --> 00:37:10,498
epistatic interactions this is just the

951
00:37:07,980 --> 00:37:13,248
significance testing of all those

952
00:37:10,498 --> 00:37:16,558
pairwise combinations across the genome

953
00:37:13,248 --> 00:37:18,919
so here's like the classic interaction

954
00:37:16,559 --> 00:37:20,810
plot this because like

955
00:37:18,920 --> 00:37:23,750
this is my favorite plot right directly

956
00:37:20,809 --> 00:37:26,840
out of Falconer I mean yeah

957
00:37:23,750 --> 00:37:31,579
so I'd say here we got like the PPD one

958
00:37:26,840 --> 00:37:33,559
allele and the PPD be one allele right

959
00:37:31,579 --> 00:37:35,329
and then depending on which allele state

960
00:37:33,559 --> 00:37:37,400
you have for each one of these if you

961
00:37:35,329 --> 00:37:40,460
have both of the non sensitive alleles

962
00:37:37,400 --> 00:37:42,710
you're really early around 100 1516 days

963
00:37:40,460 --> 00:37:44,780
if you add one of them you add about two

964
00:37:42,710 --> 00:37:48,230
days if you add the other one you add

965
00:37:44,780 --> 00:37:50,990
about you know four days and then if you

966
00:37:48,230 --> 00:37:54,639
stack them both up the you add in like

967
00:37:50,989 --> 00:37:58,369
14 14 days of the heading die so just

968
00:37:54,639 --> 00:38:00,349
beautiful classic example of these two

969
00:37:58,369 --> 00:38:02,619
alleles interacting and this and just

970
00:38:00,349 --> 00:38:05,900
like I said again this is like our

971
00:38:02,619 --> 00:38:07,670
optimal journey range this is this is

972
00:38:05,900 --> 00:38:10,039
day of the year sorry but this is the

973
00:38:07,670 --> 00:38:12,079
optimal optimal range for Wheaton Kansas

974
00:38:10,039 --> 00:38:15,320
this is pretty early you're risking like

975
00:38:12,079 --> 00:38:17,360
a lot of cold damage and frost damage

976
00:38:15,320 --> 00:38:19,250
and then this is just way too late

977
00:38:17,360 --> 00:38:21,800
you're gonna have a lot of heat stress

978
00:38:19,250 --> 00:38:23,780
in that range so the optimal varieties

979
00:38:21,800 --> 00:38:24,950
are picking one or other of those

980
00:38:23,780 --> 00:38:31,100
alleles even though they're both

981
00:38:24,949 --> 00:38:32,779
floating around the breeding program so

982
00:38:31,099 --> 00:38:35,139
the final thing then is just to say you

983
00:38:32,780 --> 00:38:37,100
know like we drove this with our tractor

984
00:38:35,139 --> 00:38:39,920
you know to give you an honest

985
00:38:37,099 --> 00:38:42,049
assessment of it it takes about so so we

986
00:38:39,920 --> 00:38:46,000
were running through on both populations

987
00:38:42,050 --> 00:38:50,050
which was around like 14

988
00:38:46,000 --> 00:38:52,150
for 1200 1300 field plots and that would

989
00:38:50,050 --> 00:38:54,550
take like a good four to five hours okay

990
00:38:52,150 --> 00:38:56,170
so is it high throughput not really you

991
00:38:54,550 --> 00:38:59,500
can go through visually about the same

992
00:38:56,170 --> 00:39:01,570
amount of time okay but you know doing

993
00:38:59,500 --> 00:39:03,639
this with a UAV is really scalable no

994
00:39:01,570 --> 00:39:05,349
actually and so here I'm just you know

995
00:39:03,639 --> 00:39:08,259
we don't have any good results from this

996
00:39:05,349 --> 00:39:11,859
but this is just to like pretend like we

997
00:39:08,260 --> 00:39:13,720
can do it okay so so this is like using

998
00:39:11,858 --> 00:39:16,659
like a really high resolution camera

999
00:39:13,719 --> 00:39:18,549
from a UAV and actually flying over

1000
00:39:16,659 --> 00:39:19,960
these plots using videos so you're

1001
00:39:18,550 --> 00:39:22,300
actually taking really high frame rate

1002
00:39:19,960 --> 00:39:24,070
and we can we can cover those plots at

1003
00:39:22,300 --> 00:39:26,260
two plots per second so we can actually

1004
00:39:24,070 --> 00:39:29,019
cover those same thousand pots in about

1005
00:39:26,260 --> 00:39:30,849
a 25 minute flight okay so now we've

1006
00:39:29,019 --> 00:39:32,949
actually gone high through but okay and

1007
00:39:30,849 --> 00:39:34,480
here just to say that it's doable or

1008
00:39:32,949 --> 00:39:36,460
theoretically right here again we don't

1009
00:39:34,480 --> 00:39:38,170
know if it's doable until we actually

1010
00:39:36,460 --> 00:39:40,960
like do the experiment for two years and

1011
00:39:38,170 --> 00:39:43,030
get the big data set and stuff but here

1012
00:39:40,960 --> 00:39:44,800
like here's an example of images from

1013
00:39:43,030 --> 00:39:46,390
there if you zoom in on that middle of

1014
00:39:44,800 --> 00:39:48,300
that plot right here you can see these

1015
00:39:46,389 --> 00:39:50,559
are headed out these are still moving

1016
00:39:48,300 --> 00:39:52,300
before they're headed out so we can

1017
00:39:50,559 --> 00:39:55,838
actually get like submillimetre pixel

1018
00:39:52,300 --> 00:39:59,289
resolution of these same plots using a

1019
00:39:55,838 --> 00:40:02,769
UAV and actually covering them you know

1020
00:39:59,289 --> 00:40:04,480
a thousand plots in 20 minutes so this

1021
00:40:02,769 --> 00:40:07,059
is like where we're really focused on

1022
00:40:04,480 --> 00:40:12,159
now taking the same approach using the

1023
00:40:07,059 --> 00:40:14,139
UAV extracted data to see if if we can

1024
00:40:12,159 --> 00:40:18,940
we can do this in a truly

1025
00:40:14,139 --> 00:40:20,500
high-throughput type of approach okay

1026
00:40:18,940 --> 00:40:22,690
so then the real question I'm sure

1027
00:40:20,500 --> 00:40:25,900
you've all been wondering now is do we

1028
00:40:22,690 --> 00:40:28,300
still need breeders okay so now we've

1029
00:40:25,900 --> 00:40:31,108
got genomic selection models that can

1030
00:40:28,300 --> 00:40:33,580
predict now which ones are the best

1031
00:40:31,108 --> 00:40:36,009
we've got like neural networks that can

1032
00:40:33,579 --> 00:40:39,309
actually do the phenotyping to get the

1033
00:40:36,010 --> 00:40:40,750
data that goes in to the models so once

1034
00:40:39,309 --> 00:40:44,529
the breeders have trained all the neural

1035
00:40:40,750 --> 00:40:46,210
networks what do we do here now so we

1036
00:40:44,530 --> 00:40:50,710
tested the same thing on a real neural

1037
00:40:46,210 --> 00:40:53,588
network ok this network was 2 years and

1038
00:40:50,710 --> 00:40:55,119
11 months old at the time of testing we

1039
00:40:53,588 --> 00:40:57,340
had one training epoch which was about

1040
00:40:55,119 --> 00:40:59,860
two minutes that's all day attention

1041
00:40:57,340 --> 00:41:04,630
we had and then we had a sample size of

1042
00:40:59,860 --> 00:41:08,320
16 spikes 8 of them were on and 8 were

1043
00:41:04,630 --> 00:41:12,579
onlus and then for this project we coded

1044
00:41:08,320 --> 00:41:14,860
them as spiky and not spiky meaning like

1045
00:41:12,579 --> 00:41:16,659
they were on or on list this was to

1046
00:41:14,860 --> 00:41:18,880
simplify you know for the new Lynette

1047
00:41:16,659 --> 00:41:20,379
we're encoded I'm a zero and one on

1048
00:41:18,880 --> 00:41:24,820
anonymous so here we coded them and

1049
00:41:20,380 --> 00:41:27,579
spiky and not spiky so here's my

1050
00:41:24,820 --> 00:41:31,500
daughter Talia Marie and let's see if

1051
00:41:27,579 --> 00:41:31,500
she can demonstrate this neural network

1052
00:41:40,590 --> 00:41:56,019
that's it so the neural network so in

1053
00:41:54,039 --> 00:41:58,989
about two minutes you can train a real

1054
00:41:56,019 --> 00:42:05,800
neural network to do what took us

1055
00:41:58,989 --> 00:42:09,909
several years and 100,000 images so

1056
00:42:05,800 --> 00:42:10,960
there's our conclusion so the high

1057
00:42:09,909 --> 00:42:12,369
throughput phenotype we're really

1058
00:42:10,960 --> 00:42:14,740
getting a production mode I think over

1059
00:42:12,369 --> 00:42:16,179
this last year or two years and they

1060
00:42:14,739 --> 00:42:17,879
were integrating that into the

1061
00:42:16,179 --> 00:42:20,409
prediction modeling where we're building

1062
00:42:17,880 --> 00:42:22,660
models that have like a vegetation index

1063
00:42:20,409 --> 00:42:25,029
assessment along with the genomic data

1064
00:42:22,659 --> 00:42:27,549
and those are actually giving a drastic

1065
00:42:25,030 --> 00:42:30,190
input okay I just briefly touched on

1066
00:42:27,550 --> 00:42:32,340
that in the beginning the exciting part

1067
00:42:30,190 --> 00:42:35,559
is we can measure some complex traits

1068
00:42:32,340 --> 00:42:37,000
using deep learning and so in my mind

1069
00:42:35,559 --> 00:42:38,469
this is really exciting new frontiers

1070
00:42:37,000 --> 00:42:40,510
because theoretically we can extend

1071
00:42:38,469 --> 00:42:42,309
those we can extend that model training

1072
00:42:40,510 --> 00:42:44,230
it's like any trait that we score right

1073
00:42:42,309 --> 00:42:46,389
all that goes into it is a whole bunch

1074
00:42:44,230 --> 00:42:48,130
of pictures images that we collected

1075
00:42:46,389 --> 00:42:50,529
high throughput in the field and then

1076
00:42:48,130 --> 00:42:53,590
whatever the breeder whenever you go out

1077
00:42:50,530 --> 00:42:55,660
and visually score right theoretically

1078
00:42:53,590 --> 00:42:57,730
can you know we can build a neural

1079
00:42:55,659 --> 00:43:01,940
network to score that same trait right

1080
00:42:57,730 --> 00:43:04,670
so then it kind of opens up like the

1081
00:43:01,940 --> 00:43:06,889
this opportunities so we know the

1082
00:43:04,670 --> 00:43:09,309
breeders are still relevant mark at

1083
00:43:06,889 --> 00:43:09,309
least for now

1084
00:43:10,519 --> 00:43:16,338
and right because somebody's got to like

1085
00:43:13,568 --> 00:43:18,800
you know assimilate all this information

1086
00:43:16,338 --> 00:43:20,960
and then figure out what to do with it

1087
00:43:18,800 --> 00:43:22,310
or at least to ask some graduate

1088
00:43:20,960 --> 00:43:24,559
students to do something with it and

1089
00:43:22,309 --> 00:43:26,150
then remember everything you need to

1090
00:43:24,559 --> 00:43:30,289
know you learned at Cornell while you

1091
00:43:26,150 --> 00:43:34,338
were here okay so thanks huge thanks to

1092
00:43:30,289 --> 00:43:38,329
Oliver everybody in my group byron

1093
00:43:34,338 --> 00:43:40,250
eavers is is our main technician that

1094
00:43:38,329 --> 00:43:42,289
manages all the field trials mark Lucas

1095
00:43:40,250 --> 00:43:43,550
I mentioned this a few times of graduate

1096
00:43:42,289 --> 00:43:46,420
students from March really critical our

1097
00:43:43,550 --> 00:43:48,829
group he's a data scientist basically

1098
00:43:46,420 --> 00:43:51,318
spends all of his time moving big data

1099
00:43:48,829 --> 00:43:55,720
around dodgy it's one of the graduate

1100
00:43:51,318 --> 00:43:57,800
students and then Kevin you Wang is

1101
00:43:55,719 --> 00:43:59,828
postdoc who was really instrumental on

1102
00:43:57,800 --> 00:44:01,789
building the actual phenotype err that

1103
00:43:59,829 --> 00:44:03,980
you know took us several years to

1104
00:44:01,789 --> 00:44:07,250
collect these datasets and then rich

1105
00:44:03,980 --> 00:44:09,318
ground is our new UAV pilot and attina

1106
00:44:07,250 --> 00:44:11,989
is another postdoc on the group who's

1107
00:44:09,318 --> 00:44:14,029
who's really helped us work through the

1108
00:44:11,989 --> 00:44:15,439
high-throughput phenotyping data our

1109
00:44:14,030 --> 00:44:17,180
computer science collaborators which

1110
00:44:15,440 --> 00:44:18,740
obviously like you know I did a

1111
00:44:17,179 --> 00:44:21,348
substantial work on this project is

1112
00:44:18,739 --> 00:44:23,889
Robert plusses group at George

1113
00:44:21,349 --> 00:44:26,780
Washington and then Hong Lang is a

1114
00:44:23,889 --> 00:44:28,549
graduate student on the project and this

1115
00:44:26,780 --> 00:44:32,329
was primarily supported through a

1116
00:44:28,550 --> 00:44:36,160
National Science Foundation plant genome

1117
00:44:32,329 --> 00:44:47,260
research program so it's

1118
00:44:36,159 --> 00:44:49,420
I'd be glad to take any questions look

1119
00:44:47,260 --> 00:44:54,460
I'm greatly relieved that readers are

1120
00:44:49,420 --> 00:44:56,139
still relevant but I how small of a park

1121
00:44:54,460 --> 00:44:59,170
and you image can you do it single one

1122
00:44:56,139 --> 00:45:02,078
major row we haven't tried single rows

1123
00:44:59,170 --> 00:45:04,599
right so the next frontier so these are

1124
00:45:02,079 --> 00:45:07,210
these are full-size plots and the trick

1125
00:45:04,599 --> 00:45:09,130
is especially with the UAV the trick is

1126
00:45:07,210 --> 00:45:12,068
because we're working on this now the

1127
00:45:09,130 --> 00:45:14,230
trick is we crop out the outside right

1128
00:45:12,068 --> 00:45:16,239
so we don't want like confounding

1129
00:45:14,230 --> 00:45:18,639
effects of like the neighboring plot and

1130
00:45:16,239 --> 00:45:20,588
so to have sting you know to go down to

1131
00:45:18,639 --> 00:45:22,389
single rows or even better like single

1132
00:45:20,588 --> 00:45:23,650
plants where you have confounding

1133
00:45:22,389 --> 00:45:25,420
effects of like stuff that's like

1134
00:45:23,650 --> 00:45:27,548
definitely wrong like something else

1135
00:45:25,420 --> 00:45:29,680
overlapping we haven't even tried to

1136
00:45:27,548 --> 00:45:33,038
touch that yet so I mean that's like the

1137
00:45:29,679 --> 00:45:34,629
real frontier but yeah so we need to do

1138
00:45:33,039 --> 00:45:41,369
it on head rows and then we'd really be

1139
00:45:34,630 --> 00:45:44,230
high through what's your next trade oh

1140
00:45:41,369 --> 00:45:45,640
yeah good question so we've actually on

1141
00:45:44,230 --> 00:45:47,650
the same data set we've got barley

1142
00:45:45,639 --> 00:45:49,710
yellow Dorf scores which is like sort of

1143
00:45:47,650 --> 00:45:53,260
a combination of like yellowing plus

1144
00:45:49,710 --> 00:45:55,150
like some anthocyanin purpling so we're

1145
00:45:53,260 --> 00:45:56,950
going to we're going to try that really

1146
00:45:55,150 --> 00:46:00,039
my next trait is to like do this exact

1147
00:45:56,949 --> 00:46:02,379
same thing just using the UAV data yeah

1148
00:46:00,039 --> 00:46:04,539
but that the trouble is like there's a

1149
00:46:02,380 --> 00:46:06,548
huge amount of pre-processing and like

1150
00:46:04,539 --> 00:46:08,829
just to get to the point where we have

1151
00:46:06,548 --> 00:46:11,619
like images that can go into the neural

1152
00:46:08,829 --> 00:46:17,710
network yeah it's a single color you

1153
00:46:11,619 --> 00:46:19,210
play around with different yeah so so

1154
00:46:17,710 --> 00:46:22,358
all of our imaging has just been with

1155
00:46:19,210 --> 00:46:24,309
like like off-the-shelf RGB cameras like

1156
00:46:22,358 --> 00:46:26,170
I didn't I didn't mention but the UAV

1157
00:46:24,309 --> 00:46:28,028
for like the vegetation index we fly

1158
00:46:26,170 --> 00:46:29,588
like multi spectral cameras the trouble

1159
00:46:28,028 --> 00:46:31,838
is the resolution on those cameras is

1160
00:46:29,588 --> 00:46:33,969
much much lower so there's really a

1161
00:46:31,838 --> 00:46:36,880
balance between I think what goes into

1162
00:46:33,969 --> 00:46:39,159
the neural networks the RGB images work

1163
00:46:36,880 --> 00:46:41,470
really good and they're more importantly

1164
00:46:39,159 --> 00:46:44,639
they're much higher resolution than what

1165
00:46:41,469 --> 00:47:10,588
we did from like multi spectral cameras

1166
00:46:44,639 --> 00:47:12,960
yeah pictures yeah just give it a date

1167
00:47:10,588 --> 00:47:16,048
and give it the images and tell you yeah

1168
00:47:12,960 --> 00:47:17,880
so so we're just like that's kind of

1169
00:47:16,048 --> 00:47:20,940
like I don't hear again I don't really

1170
00:47:17,880 --> 00:47:23,579
understand it but that's kind of like

1171
00:47:20,940 --> 00:47:25,349
the frontier of deep learning as far as

1172
00:47:23,579 --> 00:47:27,298
what these guys tell me because they're

1173
00:47:25,349 --> 00:47:29,338
you're actually putting like two levels

1174
00:47:27,298 --> 00:47:31,889
of predictors in right so you have a

1175
00:47:29,338 --> 00:47:34,259
structured data set where it's images

1176
00:47:31,889 --> 00:47:36,000
but you have to tell the network what

1177
00:47:34,260 --> 00:47:38,400
order and what time the images are from

1178
00:47:36,000 --> 00:47:39,869
and then give it a classifier right

1179
00:47:38,400 --> 00:47:41,818
so the only thing that's going into

1180
00:47:39,869 --> 00:47:43,440
these this training set is a bunch of

1181
00:47:41,818 --> 00:47:47,518
images and a bunch of classifications

1182
00:47:43,440 --> 00:47:50,460
right it can't even think on like you

1183
00:47:47,518 --> 00:47:52,318
know a next higher level so but I agree

1184
00:47:50,460 --> 00:47:55,429
that with these data sets you can

1185
00:47:52,318 --> 00:47:58,288
conceptualize like much smarter ways to

1186
00:47:55,429 --> 00:48:00,419
or much more informed ways to train them

1187
00:47:58,289 --> 00:48:29,579
that you know taking account the spatial

1188
00:48:00,420 --> 00:48:31,200
and temporal relationship and I mean

1189
00:48:29,579 --> 00:48:33,390
Mike can attest this - I think right

1190
00:48:31,199 --> 00:48:35,788
that our upper limit is like however

1191
00:48:33,389 --> 00:48:38,190
good you scored the trait right and so

1192
00:48:35,789 --> 00:48:40,319
usually I didn't listen here but like we

1193
00:48:38,190 --> 00:48:42,150
can build like digital elevation models

1194
00:48:40,318 --> 00:48:43,980
to measure plant height across the whole

1195
00:48:42,150 --> 00:48:45,869
breeding nurseries and you can actually

1196
00:48:43,980 --> 00:48:48,690
and then we benchmark that against how

1197
00:48:45,869 --> 00:48:50,039
you know you go out with the ruler and

1198
00:48:48,690 --> 00:48:52,318
measure them you're like oh there's got

1199
00:48:50,039 --> 00:48:53,579
to be minimal bias and that but we can

1200
00:48:52,318 --> 00:48:55,259
actually hit heritability x' and

1201
00:48:53,579 --> 00:48:56,640
accuracies they're better than human

1202
00:48:55,259 --> 00:48:57,838
measurements and then we try to

1203
00:48:56,639 --> 00:48:58,440
benchmark them against the human

1204
00:48:57,838 --> 00:49:02,130
measurement

1205
00:48:58,440 --> 00:49:04,769
and so it's like a catch-22 right it's a

1206
00:49:02,130 --> 00:49:06,329
well you know our ground truth is not

1207
00:49:04,769 --> 00:49:08,489
accurate but we're trying to get more

1208
00:49:06,329 --> 00:49:10,829
accurate than our ground truth so but I

1209
00:49:08,489 --> 00:49:12,598
think I think though like you know if we

1210
00:49:10,829 --> 00:49:15,150
can scale this out to many many many

1211
00:49:12,599 --> 00:49:17,010
breeding programs and you know then like

1212
00:49:15,150 --> 00:49:20,519
ever you know like multiple scores I

1213
00:49:17,010 --> 00:49:22,530
think then you kind of have the you know

1214
00:49:20,519 --> 00:49:24,900
the logic of the of the masses kind of

1215
00:49:22,530 --> 00:49:43,890
thing where it should even out over a

1216
00:49:24,900 --> 00:49:49,099
big enough data set what about you you

1217
00:49:43,889 --> 00:49:49,098
change the environment so you have

1218
00:49:58,489 --> 00:50:19,679
everything and the Cheney

1219
00:50:01,280 --> 00:50:21,329
and also the situation yeah that's good

1220
00:50:19,679 --> 00:50:22,710
so I think there's two answers that one

1221
00:50:21,329 --> 00:50:23,818
like I think if we do it across the

1222
00:50:22,710 --> 00:50:25,740
nephew years and enough different

1223
00:50:23,818 --> 00:50:27,568
breeders and programs then you kind of

1224
00:50:25,739 --> 00:50:31,048
see all of the variants that are you

1225
00:50:27,568 --> 00:50:31,288
know morphological variants that are out

1226
00:50:31,048 --> 00:50:32,759
there

1227
00:50:31,289 --> 00:50:34,260
the other one is though that there's

1228
00:50:32,760 --> 00:50:37,710
opportunities to like actually train

1229
00:50:34,260 --> 00:50:40,410
this in season like right so you could

1230
00:50:37,710 --> 00:50:43,380
actually take data visually on a small

1231
00:50:40,409 --> 00:50:46,230
number of plots and then in season train

1232
00:50:43,380 --> 00:50:47,849
these type of things onto like fifty

1233
00:50:46,230 --> 00:50:50,130
thousand plots that you don't have the

1234
00:50:47,849 --> 00:50:51,240
physical capacity to score and that's

1235
00:50:50,130 --> 00:50:53,130
especially the way we're thinking about

1236
00:50:51,239 --> 00:50:54,778
it for just the vegetation index right

1237
00:50:53,130 --> 00:50:57,088
well build the model will actually

1238
00:50:54,778 --> 00:50:59,219
measure yield on like a thousand plots

1239
00:50:57,088 --> 00:51:01,650
and then use that information to predict

1240
00:50:59,219 --> 00:51:04,399
yield in the same environment to like

1241
00:51:01,650 --> 00:51:04,400
fifty thousand

1242
00:51:13,599 --> 00:51:19,849
yeah yes this scoring was all done by

1243
00:51:17,300 --> 00:51:21,710
Byron right so we just had one score all

1244
00:51:19,849 --> 00:51:23,599
right so this is benchmarked across so

1245
00:51:21,710 --> 00:51:27,250
we don't really have the confounding

1246
00:51:23,599 --> 00:51:27,250
effects of multiple people being biased

1247
00:51:27,849 --> 00:51:37,250
oh yeah yeah so the same person there's

1248
00:51:33,829 --> 00:51:40,759
there's really minimal internal there's

1249
00:51:37,250 --> 00:51:42,170
the internal bias so like like I mean we

1250
00:51:40,760 --> 00:51:43,490
had very few time points where it was

1251
00:51:42,170 --> 00:51:44,599
like you go out one day and then you go

1252
00:51:43,489 --> 00:51:45,919
out the next day and you actually score

1253
00:51:44,599 --> 00:51:49,569
it lower than you did the time before

1254
00:51:45,920 --> 00:51:49,570
right so we're really not

1255
00:51:54,190 --> 00:52:11,679
yeah that's within one person it's

1256
00:51:55,929 --> 00:52:19,629
pretty minimal and there's a certain C

1257
00:52:11,679 --> 00:52:21,789
in the yeah the same thing again we I

1258
00:52:19,630 --> 00:52:23,200
don't know yeah I don't know which one's

1259
00:52:21,789 --> 00:52:24,639
wrong I need to go back and probably run

1260
00:52:23,199 --> 00:52:27,929
those models again and see which one has

1261
00:52:24,639 --> 00:52:31,179
like a better fit on you know like a

1262
00:52:27,929 --> 00:52:32,230
smaller error on fitting those maybe but

1263
00:52:31,179 --> 00:52:56,379
yeah here again like how do you know

1264
00:52:32,230 --> 00:52:57,760
what's right I grew I grew that's much

1265
00:52:56,380 --> 00:53:14,769
easier way to like to see which has

1266
00:52:57,760 --> 00:53:18,550
higher ability they were the same me for

1267
00:53:14,769 --> 00:53:24,570
like heading date now we haven't looked

1268
00:53:18,550 --> 00:53:24,570
at that yeah that's a good one yeah

1269
00:53:24,630 --> 00:53:28,090
there should be some spec let me know

1270
00:53:26,860 --> 00:53:29,260
well we know for sure that there's a

1271
00:53:28,090 --> 00:53:30,760
spectral difference between before

1272
00:53:29,260 --> 00:53:32,530
they're headed and after they're headed

1273
00:53:30,760 --> 00:53:33,790
whether you can actually get like some

1274
00:53:32,530 --> 00:53:34,660
percentage that would be a cure enough

1275
00:53:33,789 --> 00:53:36,969
to squirt a date

1276
00:53:34,659 --> 00:53:39,129
during that progression yeah we don't

1277
00:53:36,969 --> 00:53:40,719
know the other trouble is we don't we

1278
00:53:39,130 --> 00:53:42,140
don't fly the hyperspectral but like

1279
00:53:40,719 --> 00:53:48,250
once a week

1280
00:53:42,139 --> 00:53:48,250
no but that's good idea we should try it

1281
00:53:50,559 --> 00:53:55,339
there's an error from scoring and

1282
00:53:52,760 --> 00:53:56,900
there's an error from you know some plot

1283
00:53:55,338 --> 00:53:58,759
set out earlier because they're a little

1284
00:53:56,900 --> 00:54:05,480
drier later

1285
00:53:58,760 --> 00:54:07,220
so you feed the deviation of the actual

1286
00:54:05,480 --> 00:54:12,920
heading from the expected from the

1287
00:54:07,219 --> 00:54:15,379
genotype into a at CNN and so they would

1288
00:54:12,920 --> 00:54:16,940
try to predict whether okay it's heading

1289
00:54:15,380 --> 00:54:20,510
on this date but I think it's probably

1290
00:54:16,940 --> 00:54:23,858
early relative to what the genotype like

1291
00:54:20,510 --> 00:54:27,559
put some genetic information into there

1292
00:54:23,858 --> 00:54:32,139
I'm sure somewhere or get it to try to

1293
00:54:27,559 --> 00:54:32,140
predict that other component of error

1294
00:54:35,920 --> 00:54:40,490
yeah that was a little biased in the

1295
00:54:38,568 --> 00:54:41,960
breeding program yeah within the

1296
00:54:40,489 --> 00:54:44,449
breeding program though you don't really

1297
00:54:41,960 --> 00:54:46,179
have those major effects still

1298
00:54:44,449 --> 00:54:49,298
segregating

1299
00:54:46,179 --> 00:54:50,348
right but I mean that's if I'm

1300
00:54:49,298 --> 00:54:51,548
understand your question right that's

1301
00:54:50,349 --> 00:54:53,528
like along the lines of what we're

1302
00:54:51,548 --> 00:54:55,538
thinking on is actually putting would

1303
00:54:53,528 --> 00:55:02,139
you be even okay so here's our here's

1304
00:54:55,539 --> 00:55:06,309
our sci-fi idea is to actually yeah yeah

1305
00:55:02,139 --> 00:55:08,019
yeah so maybe we actually got some fun

1306
00:55:06,309 --> 00:55:10,298
new spatial models that actually like

1307
00:55:08,019 --> 00:55:12,460
they're like Auto regressive models

1308
00:55:10,298 --> 00:55:14,829
except because we've mapped these things

1309
00:55:12,460 --> 00:55:16,720
in physical coordinates we apply like an

1310
00:55:14,829 --> 00:55:19,298
actual physical correction those

1311
00:55:16,719 --> 00:55:20,730
actually perform really well so I would

1312
00:55:19,298 --> 00:55:23,170
say maybe that's an easier way than

1313
00:55:20,730 --> 00:55:24,278
doing it through the neural net but yeah

1314
00:55:23,170 --> 00:55:26,139
I know what you're saying like somehow

1315
00:55:24,278 --> 00:55:27,909
feed into the neural network that these

1316
00:55:26,139 --> 00:55:30,730
two plots are next to each other versus

1317
00:55:27,909 --> 00:55:31,319
these two are like clear across the

1318
00:55:30,730 --> 00:55:34,498
field

1319
00:55:31,320 --> 00:55:34,499
[Music]

1320
00:55:42,610 --> 00:55:49,769
[Applause]

1321
00:55:46,730 --> 00:55:55,548
this has been a production of Cornell

1322
00:55:49,769 --> 00:55:55,548
University on the web at Cornell edu

