[SPEAKER_02]: This is a production of Cornell
University.
[SPEAKER_02]: Thanks, Jacob.
[SPEAKER_02]: And sorry for the mouthful of a title.
[SPEAKER_02]: I shortened it a little bit for here.
[SPEAKER_02]: But oh, well.
[SPEAKER_02]: OK.
[SPEAKER_02]: So building off of what Evan said about
cassava already, I'll just jump right in.
[SPEAKER_02]: Some of the major cassava breeding targets
that the programs in the NextGen group
[SPEAKER_02]: work on are pest and disease resistance,
[SPEAKER_02]: including CBSD or cassava brown streak
disease.
[SPEAKER_02]: This is the root on the left, and then
cassava mosaic virus, which is mosaicing
[SPEAKER_02]: on the leaf here.
[SPEAKER_02]: Yield and field performance, so the number
of roots per plant, the size of the roots,
[SPEAKER_02]: as shown here.
[SPEAKER_02]: And then quality traits.
[SPEAKER_02]: And these are all part of the selection
indices that are used by the breeding
[SPEAKER_02]: programs.
[SPEAKER_02]: Today I'm going to focus mostly on this
quality trait part.
[SPEAKER_02]: And the actual measurement that's put into
the selection index is the root dry matter
[SPEAKER_02]: content.
[SPEAKER_02]: This is the percent of the root that's not
water, and that's calculated by the dry
[SPEAKER_02]: weight over the fresh weight times 100%.
[SPEAKER_02]: It's a major component of the dry yield
and the food quality.
[SPEAKER_02]: So it factors into needs of both
processors, farmers, and consumers.
[SPEAKER_02]: It typically ranges from 20% to 45%,
with the higher the better.
[SPEAKER_02]: The 20% is not something you'd actually
want to eat or grow.
[SPEAKER_02]: And it's not uniform within the root,
which is something I'll come back to
[SPEAKER_02]: later.
[SPEAKER_02]: The dry matter content's mostly made up of
starches, carbohydrates, with some
[SPEAKER_02]: protein, fiber, ash, lipids as well.
[SPEAKER_02]: So though it's really important for
breeding programs, it's time consuming and
[SPEAKER_02]: laborious to measure.
[SPEAKER_02]: So in Uganda, the roots are graded by
hand.
[SPEAKER_02]: They're dried in big ovens.
[SPEAKER_02]: And when you consider that there could be
thousands of plots per breeding program,
[SPEAKER_02]: per season, and limited electricity that
could make the ovens go offline,
[SPEAKER_02]: and then off-site trials that you have to
transport the roots back and forth,
[SPEAKER_02]: that creates a lot of work.
[SPEAKER_02]: So the goal is to reduce the amount of
work that breeding programs have to do
[SPEAKER_02]: each season.
[SPEAKER_02]: And that's where near-infrared
spectroscopy comes in.
[SPEAKER_02]: And this has been used before in Cassava,
but I'll explain a little bit about what
[SPEAKER_02]: it is.
[SPEAKER_02]: So this is looking at the reflectance in
the near-infrared region of the
[SPEAKER_02]: electromagnetic spectrum.
[SPEAKER_02]: This is 780 to 2,500 nanometers,
so just beyond the visible.
[SPEAKER_02]: It's measured by using an active light
source that emits wavelengths in this
[SPEAKER_02]: range on a biological sample.
[SPEAKER_02]: And then the sample itself changes the
reflectance pattern that's sensed by a
[SPEAKER_02]: sensor.
[SPEAKER_02]: And so this is what Cassava looks like
when you scan it with a near-infrared
[SPEAKER_02]: spectrometer.
[SPEAKER_02]: So we see reflectance on the y-axis and
wavelengths on the x.
[SPEAKER_02]: And this tells us about the chemical and
physical properties of the sample that was
[SPEAKER_02]: scanned.
[SPEAKER_02]: But the signal that comes back is complex.
[SPEAKER_02]: And so it requires multivariate
statistical techniques to decipher what's
[SPEAKER_02]: actually going on.
[SPEAKER_02]: But once you have models calibrated for
the traits of interest, you can measure
[SPEAKER_02]: these traits quickly and
non-destructively.
[SPEAKER_02]: So like I said, it's been used before in
Cassava to look at dry matter content in
[SPEAKER_02]: roots.
[SPEAKER_02]: This has been done, first of all,
with the FOSS 6500.
[SPEAKER_02]: This is a benchtop model that's been shown
to be highly predictive of dry matter
[SPEAKER_02]: content, so above 0.94 in the literature.
[SPEAKER_02]: And then we have a spectral range here
that includes some of the visible range as
[SPEAKER_02]: well, from 400 to 2,500 nanometers.
[SPEAKER_02]: The next generation was from Ugo Ikeogu
from Jean-Luc's lab.
[SPEAKER_02]: And he looked at this mobile spectrometer,
the quality spec track.
[SPEAKER_02]: It has an even larger spectral range,
but the predictive ability dropped a
[SPEAKER_02]: little bit in his test to 0.8,
which is still pretty good.
[SPEAKER_02]: And it passed the standards for breeders.
[SPEAKER_02]: But the problem with these two units is
they're really expensive.
[SPEAKER_02]: And for a small breeding program,
this might be way out of the budget.
[SPEAKER_02]: You could fund extra workers.
[SPEAKER_02]: You could put extra field plots,
do more trials for this amount of money.
[SPEAKER_02]: So for these reasons, we've been looking
into the SIO, which is a small handheld
[SPEAKER_02]: spectrometer that's only $300 per unit.
[SPEAKER_02]: But it does have a smaller spectral range.
[SPEAKER_02]: And this means that we need to evaluate
the performance of this spectrometer
[SPEAKER_02]: before we can fully recommend it to
breeding programs.
[SPEAKER_02]: In order to do that, we collect
calibration data, so scans from the
[SPEAKER_02]: spectrometer paired with these oven
measurements that I was talking about
[SPEAKER_02]: before.
[SPEAKER_02]: We use those as input for prediction model
development.
[SPEAKER_02]: And once we have models that pass our
standards, we can use them routinely in
[SPEAKER_02]: breeding programs.
[SPEAKER_02]: But to get to that point, we need to
optimize the protocols that we're using,
[SPEAKER_02]: both in actual sampling of the roots and
in model development.
[SPEAKER_02]: And then we do need to keep going back and
making sure that our models are still
[SPEAKER_02]: appropriate as our populations change and
we have new generations.
[SPEAKER_02]: So the calibration data collection looks
like selecting several roots for plot and
[SPEAKER_02]: then slicing them.
[SPEAKER_02]: So we have three different slice points.
[SPEAKER_02]: And that is so that we can cover the
variation within the root.
[SPEAKER_02]: These root slices are each scanned with
the spectrometer.
[SPEAKER_02]: And then we take a mean plot dry matter
content measurement using the oven method
[SPEAKER_02]: that I talked about earlier.
[SPEAKER_02]: And these scans are paired with these
measurements.
[SPEAKER_02]: And those go into our prediction models.
[SPEAKER_02]: So these are the populations that I've
been working with so far.
[SPEAKER_02]: The dry matter content varies pretty
widely both within and among both trials
[SPEAKER_02]: and breeding programs.
[SPEAKER_02]: I want to point out a couple things here.
[SPEAKER_02]: First is these two trials at EMBRAFA in
Brazil are seedling evaluation trials.
[SPEAKER_02]: And if you talk to any cassava breeder,
you'll know that seedling evaluation
[SPEAKER_02]: trials from True Seed are not always
indicative of what the plant will actually
[SPEAKER_02]: do when you take a clonal propagule from
it.
[SPEAKER_02]: So we see a wide range of dry matter
content in those two.
[SPEAKER_02]: These two trials from IITA are actually
the same genotypes grown in two different
[SPEAKER_02]: years.
[SPEAKER_02]: So we do see a lot of variation due to
environment here.
[SPEAKER_02]: And then this trial at NACRI has a low
tail here for dry matter content.
[SPEAKER_02]: And that is because of CBSD incidents in
Uganda.
[SPEAKER_02]: So that's those diseased roots from that
first slide that I showed.
[SPEAKER_02]: And that really affects the dry matter
content.
[SPEAKER_02]: So once we have these oven dry matter
content measurements paired with our
[SPEAKER_02]: scans, we can use those to create
prediction models.
[SPEAKER_02]: So I divide them into training and test
sets and then use five-fold
[SPEAKER_02]: cross-validation to tune partially squares
model parameters with the training set and
[SPEAKER_02]: then use the optimized model to predict
our test set.
[SPEAKER_02]: I output model performance statistics like
R squared, root mean squared error.
[SPEAKER_02]: And then I repeat this with different
subsets of training and test sets.
[SPEAKER_02]: So when we look at performance within
breeding programs, so that's the diagonal.
[SPEAKER_02]: This is not a correlation matrix.
[SPEAKER_02]: It is a training set on the y-axis,
test set on the x.
[SPEAKER_02]: This is whole breeding program
performance.
[SPEAKER_02]: So we can see up in the top left is using
IITA data to predict IITA data and then so
[SPEAKER_02]: on.
[SPEAKER_02]: So this is in 2018.
[SPEAKER_02]: We see that model performance is pretty
high.
[SPEAKER_02]: We got 0.85 R squared with a 2.6 RMSE for
IITA.
[SPEAKER_02]: And then going down there.
[SPEAKER_02]: But the real test would be to see how the
models perform when you're training on one
[SPEAKER_02]: breeding program and testing another.
[SPEAKER_02]: So can we train models at IITA and test
them in Rwanda, say?
[SPEAKER_02]: The answer is mixed bag.
[SPEAKER_02]: We have some models doing really well,
like using the EMBRAPA data to predict the
[SPEAKER_02]: plots at NACRI.
[SPEAKER_02]: But then when you use IITA, we're getting
poor performance predicting either of the
[SPEAKER_02]: other breeding programs.
[SPEAKER_02]: This is a little concerning, but again,
we could just train models for each
[SPEAKER_02]: individual breeding program.
[SPEAKER_02]: Ideally though, we would use everything we
have and train like a major model and then
[SPEAKER_02]: use that to test everything.
[SPEAKER_02]: And so when we do that, we actually see
the performance go back up, which is
[SPEAKER_02]: pretty great.
[SPEAKER_02]: So this is really comparable to this
diagonal here.
[SPEAKER_02]: We only lose very small amounts of our
predictive ability.
[SPEAKER_02]: But in order to make these big models
using everything we have, we have to be
[SPEAKER_02]: able to put everything together in one
place.
[SPEAKER_02]: So this is where CassavaBase comes in.
[SPEAKER_02]: I've been working with Lucas Mueller's
group to create the infrastructure to
[SPEAKER_02]: store and access spectral data within
CassavaBase.
[SPEAKER_02]: And this will allow for us to take
training and test sets from any trial
[SPEAKER_02]: within the database and then use them to
build and evaluate models.
[SPEAKER_02]: So the functions that I've been writing
and using for my own work, we're putting
[SPEAKER_02]: into CassavaBase for use by any breeder.
[SPEAKER_02]: And then they can build, evaluate their
own models and use them for prediction.
[SPEAKER_02]: And then the predicted values can be used
for selection in those selection indices
[SPEAKER_02]: that I've been talking about.
[SPEAKER_02]: So that's our plan moving forward.
[SPEAKER_02]: But I'd really like to thank all of the
NextGen Cassava breeding programs,
[SPEAKER_02]: the GoreLab, the FinoApps team,
my committee, and then the funding from
[SPEAKER_02]: the FinoApps project.
[SPEAKER_02]: So with that, I'll take questions.
[SPEAKER_02]: Yeah, Evan?
[SPEAKER_02]: So by combining two, you mean two
programs?
[SPEAKER_01]: Yeah,
[SPEAKER_02]: so here what I did is train on two
programs and like 70% of the third and
[SPEAKER_02]: then test on that 30% holdout.
[SPEAKER_02]: So I haven't tried training a model on,
say, IIT and ACRI and predicting EMBRAFA,
[SPEAKER_02]: but that's definitely something that I can
do.
[SPEAKER_02]: Thanks.
[SPEAKER_02]: Yeah, Ed?
[SPEAKER_01]: When you do this training here,
does your model get to see which
[SPEAKER_01]: environment they came up with if you only
showed the spectra?
[SPEAKER_02]: So for here, I'm just training it on the
spectra, but I do have test plots from all
[SPEAKER_02]: of the environments included in the
training set.
[SPEAKER_02]: So I also have done cross-validation
schemes that hold out an entire
[SPEAKER_02]: environment or specific genotypes.
[SPEAKER_02]: And those, as you'd expect, perform a
little more poorly.
[SPEAKER_02]: Than these do.
[SPEAKER_01]: But this looks really nice.
[SPEAKER_02]: Yeah, it is pretty exciting.
Yeah,
[SPEAKER_02]: so the question was, could I subset the
data from the spectrometers with a larger
[SPEAKER_02]: range to my smaller range?
[SPEAKER_02]: And compare how they do compared to this
one.
[SPEAKER_02]: Yes, we actually did that before starting
with Ugo's data is take a subset from 740
[SPEAKER_02]: to 1070 nanometers, which is the SIOS
range.
[SPEAKER_02]: And saw pretty high performance.
[SPEAKER_02]: I don't remember the exact numbers off the
top of my head.
[SPEAKER_02]: But in the high 0.8s for dry matter
content, we also looked at carotenoid
[SPEAKER_02]: content for that and saw it was,
as expected, pretty low because most of
[SPEAKER_02]: the signal for carotenoids is in the
visible range, which is outside the range
[SPEAKER_02]: of the SIOS.
[SPEAKER_02]: So that's why we went ahead and moved
forward with the dry matter content.
[SPEAKER_02]: Yeah, thank you.
[SPEAKER_00]: Are there any questions over Zoom?
[SPEAKER_00]: OK, well, thank you very much,
Jenna.
Thank you.
[SPEAKER_02]: This has been a production of Cornell
University on the web at cornell.edu.
[SPEAKER_02]: Thank you.
[SPEAKER_02]: Thank you.
Thank you.
