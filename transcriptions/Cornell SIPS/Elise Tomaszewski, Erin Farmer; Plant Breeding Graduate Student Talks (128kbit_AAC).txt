[SPEAKER_02]: This is a production of Cornell
University.
[SPEAKER_00]: Okay, so hi everyone, my name is Elise
Tomaszowski.
[SPEAKER_00]: I'm really excited to talk about my
research where I've been using CRISPR-Cas9
[SPEAKER_00]: to target fruit obsidian-related genes in
Fissilis grisea, and I'll also go over an
[SPEAKER_00]: unexpected path that my research has taken
over the last couple of years.
[SPEAKER_00]: So Fissilis grisea, or ground cherry,
is my model species.
[SPEAKER_00]: It's a species that I work on.
[SPEAKER_00]: It is a Solanaceous fruit crop species,
and it produces small sweet yellow
[SPEAKER_00]: berries.
[SPEAKER_00]: However, it is an underutilized species
that's not grown on a larvae.
[SPEAKER_00]: The fruit are covered by an inflated
calyx, or a husk, and the husk of them
[SPEAKER_00]: color does not always correlate with the
ripeness of the fruit.
[SPEAKER_00]: So on the left are fruit that have
dropped, and I peel back the calyx seeds
[SPEAKER_00]: of all of these, and there is a clear
gradient of ripeness in the fruit.
[SPEAKER_00]: So even though they have dropped,
they are not always ripe.
[SPEAKER_00]: Not only is that an issue, but the fruit
drop is an issue because you can then
[SPEAKER_00]: introduce soil-borne pests or pathogens to
the fruit, and making them unsellable,
[SPEAKER_00]: and farmers will lose in profit that way.
[SPEAKER_00]: Therefore, for my research, I am using
CRISPR-Cas9 and Fissilis grisea as my
[SPEAKER_00]: model species to explore the genetics
behind fruit obsidian, as well as trying
[SPEAKER_00]: to develop ground cherry lines with
reduced fruit drop.
[SPEAKER_00]: There are four main steps of fruit
obsidian or fruit drop.
[SPEAKER_00]: However, the genetics behind each step is
largely unknown.
[SPEAKER_00]: These four steps include the formation of
an obsidian zone, which are small,
[SPEAKER_00]: cytoplasmically dense cells.
[SPEAKER_00]: This is where the detachment occurs,
and it forms on the pedestal that connects
[SPEAKER_00]: the fruit to the plant.
[SPEAKER_00]: These obsidian zone cells then become
competent to external signals that induce
[SPEAKER_00]: cell separation, and then senescence and
detachment occurs.
[SPEAKER_00]: For my research, though, I am interested
in understanding the genetics behind the
[SPEAKER_00]: obsidian zone formation and how that
occurs.
[SPEAKER_00]: A likely group of genes for me to target
were Madbox transcription factors.
[SPEAKER_00]: These are largely known to upregulate or
induce floral organ development,
[SPEAKER_00]: and they're also known to work in groups
of four or a tetra.
[SPEAKER_00]: In tomato, which I'm kind of illustrating
on the left here, there are three known
[SPEAKER_00]: Madbox transcription factors that induce
obsidian zone development.
[SPEAKER_00]: These include jointless.
[SPEAKER_00]: What I'm showing is a wild-type tomato
pedestal on the top and a jointless mutant
[SPEAKER_00]: pedestal on the bottom.
[SPEAKER_00]: There is no obsidian zone.
[SPEAKER_00]: This is also the same for mutants of
macrocalyx, where MC, as my diagram shows,
[SPEAKER_00]: and jointless 2.
[SPEAKER_00]: However, interestingly, the jointless 2
ortholog does not exist in Vesclis Grisea,
[SPEAKER_00]: and I'll talk about that more at the end
of my presentation.
[SPEAKER_00]: But for my work, I'm using CRISPR-Cas9 to
target the ortholog of macrocalyx,
[SPEAKER_00]: which is MPF3, and the ortholog of
jointless, which is also named jointless.
[SPEAKER_00]: And I hypothesized that knocking out these
genes would also inhibit or not have an
[SPEAKER_00]: obsidian zone form on the pedestal.
[SPEAKER_00]: And that is exactly what I found.
[SPEAKER_00]: So on the left is a wild-type brown cherry
fruit, and zooming in, it's very clear
[SPEAKER_00]: where this obsidian zone is present.
[SPEAKER_00]: This is where the senescence stops on the
pedestal.
[SPEAKER_00]: This is where the fruit will detach.
[SPEAKER_00]: However, in my mutant in the middle here,
this obsidian zone does not exist.
[SPEAKER_00]: It's not present by the naked eye.
[SPEAKER_00]: In fact, these fruit will continue to stay
on the plant and actually decay or
[SPEAKER_00]: continue to ripen until a physical force
is applied.
[SPEAKER_00]: However, I do want to note that it's not
impossible to pull these fruit off.
[SPEAKER_00]: It's not harming the plant like it would
in a pet sapper or golden berry.
[SPEAKER_00]: Similarly to my jointless mutants,
my MPF3 mutants also do not form an
[SPEAKER_00]: obsidian zone, shown in the middle picture
here as well.
[SPEAKER_00]: Another phenotype that I'm seeing on these
MPF3 mutants only is that the calyx does
[SPEAKER_00]: not coalesce to a single point,
as it does in the wild-type.
[SPEAKER_00]: You can also see the berry in there.
[SPEAKER_00]: It's completely yellow, so it's already
ripened, which is a great phenotype that I
[SPEAKER_00]: like to see.
[SPEAKER_00]: And it's helping with the uniformity of
ripening.
[SPEAKER_00]: So just because I couldn't see the
obsidian zone by eye doesn't mean I didn't
[SPEAKER_00]: form, and I wanted to see on a microscopic
level if the obsidian zone was forming.
[SPEAKER_00]: So what I did was I chose fruit that the
calyx or the fruit was starting to ripen.
[SPEAKER_00]: I embedded those in paracin wax and
sectioned those.
[SPEAKER_00]: And what I saw was an obsidian zone in my
wild-type, so on the very left.
[SPEAKER_00]: What you can puddle in yourself is that on
the left would be the pedestal connecting
[SPEAKER_00]: to the plant, and towards the right would
be connecting to the fruit.
[SPEAKER_00]: There is a clear zone of obsidian zone
cells.
[SPEAKER_00]: They're small and darkly staked.
[SPEAKER_00]: However, in my jointless mutant,
shown in the middle here, this obsidian
[SPEAKER_00]: zone is not present.
[SPEAKER_00]: I don't see these small banding cells.
[SPEAKER_00]: Similarly, in my MPF3 mutant, this also
doesn't exist.
[SPEAKER_00]: This is exactly what I wanted to see.
[SPEAKER_00]: Zooming out, we're on a larger scale.
[SPEAKER_00]: This is also important, both not only in a
large-scale agricultural setting,
[SPEAKER_00]: but in the greenhouse.
[SPEAKER_00]: So I grew up wild-type plants,
and my mutants both join this MPF3.
[SPEAKER_00]: And these are about the same time.
[SPEAKER_00]: Everything's the same.
[SPEAKER_00]: And you can see the large accumulation of
fruit occurring on the rakes that hold up
[SPEAKER_00]: the plant.
[SPEAKER_00]: Not only does this cause more time for me
as a researcher to have to go and clean my
[SPEAKER_00]: greenhouses, but you're increasing
pressure of both diseases and pests in the
[SPEAKER_00]: greenhouse.
[SPEAKER_00]: Similarly, as I've already stated,
on a large scale, this would be bad
[SPEAKER_00]: because you'd be losing profit due to
fruit that are on the ground.
[SPEAKER_00]: So my mutants are holding up, and they're
dropping maybe one or two fruit,
[SPEAKER_00]: likely because you're bumping into them
wherever they are.
[SPEAKER_00]: Up until this point, you guys have kindly
assumed that I have created knockouts.
[SPEAKER_00]: However, the last couple of years,
I've had a lot of issues detecting what
[SPEAKER_00]: edits I've made using CRISPR-Cas-Net.
[SPEAKER_00]: I couldn't produce an amplicon using PCR
despite many different methods and
[SPEAKER_00]: attempts.
[SPEAKER_00]: And looking further, I found that my
region is rich in tandem A-T repeats,
[SPEAKER_00]: which makes PCR an awful nightmare.
[SPEAKER_00]: So I found a PCR protocol from
daughter-well and colleagues where they
[SPEAKER_00]: use a two-step PCR method, and they lower
the extension temperature and increase the
[SPEAKER_00]: amount of yeast they deploy.
[SPEAKER_00]: Typically, an extension temperature of 72
degrees is used, and I couldn't get an
[SPEAKER_00]: amplicon, shown by this gel here.
[SPEAKER_00]: So when I lower the extension temperature
to 68 degrees, I was able to get an
[SPEAKER_00]: amplicon.
[SPEAKER_00]: So using that method and my optimized
protocol, I finally got bands,
[SPEAKER_00]: which I was really excited for.
[SPEAKER_00]: So it's clear the band on the very right
is my wild type, and all of my alleles are
[SPEAKER_00]: evidence of deletions in the gene itself.
[SPEAKER_00]: This is rejoinous, by the way.
[SPEAKER_00]: However, this was also concerning to me,
because Fissilis grisae is reported to be
[SPEAKER_00]: a diploid.
[SPEAKER_00]: So at maximum, I should be getting two
edited alleles, and I'm seeing three bands
[SPEAKER_00]: in most of my examples here.
[SPEAKER_00]: This indicated to me that these weren't
actually diploids, so I had to figure this
[SPEAKER_00]: out.
[SPEAKER_00]: And I did this with two-way.
[SPEAKER_00]: First, with a pollen germination screen
that was adapted from the Lippmann lab,
[SPEAKER_00]: where they found that diploid plants had
one pollen tube per pollen grain.
[SPEAKER_00]: However, non-diploids would have a mixture
of two pollen tubes per pollen grain.
[SPEAKER_00]: What I'm showing on the left here is a
picture of my wild type Fissilis grisae
[SPEAKER_00]: pollen.
[SPEAKER_00]: And thankfully for me, these all have one
pollen tube per pollen grain, meaning that
[SPEAKER_00]: my stock is, in fact, diploid.
[SPEAKER_00]: What I'm showing now are pictures of my
mutants from joinless.
[SPEAKER_00]: So the top two here, they have these two
pollen tubes for pollen grain,
[SPEAKER_00]: as well as this bottom left one here,
indicating to me that they're not diploid.
[SPEAKER_00]: Also, interestingly, my non-transformed
control, or my wild type that went through
[SPEAKER_00]: regeneration, also had two pollen tubes
per pollen grain.
[SPEAKER_00]: This is actually good for me because now I
have a tetraploid wild type that I can use
[SPEAKER_00]: for comparison.
[SPEAKER_00]: I kind of already spoiled it a little bit,
but I then needed to use flow cytometry to
[SPEAKER_00]: kind of figure out what was going on,
if I had an aneuploid, a hexaploid,
[SPEAKER_00]: or a tetraploid.
[SPEAKER_00]: So I was using leaf tissue with the help
of Lena Wilson, and essentially what you
[SPEAKER_00]: can do with flow cytometry is estimate
your tetraploid, or your ploidy level,
[SPEAKER_00]: based on the nuclear fluorescence.
[SPEAKER_00]: So essentially, a diploid would have half
the amount of fluorescence as a
[SPEAKER_00]: tetraploid, and this would be shown by an
increase on the x-axis.
[SPEAKER_00]: So on the left, you have a diploid peak at
50, and on the right, you have a
[SPEAKER_00]: tetraploid peak at 100.
[SPEAKER_00]: For my samples, this is exactly what I
saw.
[SPEAKER_00]: So on the left is my wild type,
and I had a fluorescence level of 10,000,
[SPEAKER_00]: but my non-transformed control,
or the tetraploid wild type that I
[SPEAKER_00]: expected, was at 20,000, doubling the
fluorescence peak, indicating to me that
[SPEAKER_00]: it was a tetraploid.
[SPEAKER_00]: This was also the case for my jointless
plants, as well as my MPF3 plants.
[SPEAKER_00]: So before I go on to what's next,
I also want to sympathize greatly with
[SPEAKER_00]: those who work with polyploid plants.
[SPEAKER_00]: This has been a lot of work, but I still
have a lot more to go.
[SPEAKER_00]: I'm in the process of trying to identify
other mass box transcription factors that
[SPEAKER_00]: interact with jointless and MPF3,
seeing what might have taken the place of
[SPEAKER_00]: jointless, too.
[SPEAKER_00]: Once I get candidates, I plan to target
them using CRISPR and also screen those
[SPEAKER_00]: for any obsessions on phenotypes.
[SPEAKER_00]: And with that, I'd like to thank all of
our committee members, all of the members
[SPEAKER_00]: from the BANAC and Gia Bononi Labs,
as well as the BTI Greenhouse staff for
[SPEAKER_00]: keeping my plants healthy and happy.
[SPEAKER_00]: The flow cytometry team, especially Lena
Wilson and Jackie Mahoney, as well as the
[SPEAKER_00]: Lippman Lab members, Sergey and Mauta from
BTI for their help with the microscopy
[SPEAKER_00]: work, as well as Victoria and Tismark,
who are my R&U students, Joseph Hill,
[SPEAKER_00]: who helped a lot with the PCR
troubleshooting, and last but not least,
[SPEAKER_00]: Nathan Green, who was a former member of
the BANAC Lab, who helped with the
[SPEAKER_00]: jointless CRISPR construct design,
as well as generating the MPF3 genes.
[SPEAKER_00]: And with that, I'm happy to take any
questions.
[SPEAKER_01]: Very nice.
[SPEAKER_01]: Is it easier to look at pollen than it is
to look at root tips for funnier?
[SPEAKER_00]: I was also considering doing that.
[SPEAKER_00]: Because the protocol for this list in the
pollen had already been figured out,
[SPEAKER_00]: it was a three-hour protocol for me.
[SPEAKER_00]: So I could collect pollen, germinate it,
and then I was looking in the microscope
[SPEAKER_00]: three to four hours later.
[SPEAKER_00]: So it worked well for me.
[SPEAKER_00]: I could use the root tips wash.
[SPEAKER_01]: It took about three hours.
[SPEAKER_00]: Yeah, three to four.
[SPEAKER_00]: I don't want to be this person here.
[SPEAKER_01]: So while he's doing that, I promise they
do.
[SPEAKER_00]: What really started this off for me was I
was in the greenhouse and I noticed that
[SPEAKER_00]: my flowers were incredibly large.
[SPEAKER_00]: I thought I was kind of going crazy for a
second there.
[SPEAKER_00]: But the flowers are very large,
and if you'd be able to get this up,
[SPEAKER_00]: I'll show you.
[SPEAKER_00]: The other thing I noticed in the flowers
themselves was deeper anthocyanin
[SPEAKER_00]: pigmentation.
[SPEAKER_00]: But you'll also have larger leaves.
[SPEAKER_00]: They're a lot greener.
[SPEAKER_00]: So I can pretty easily detect a tetraploid
versus a diploid.
[SPEAKER_00]: If it ever comes back, you'll be able to
see it.
[SPEAKER_00]: So not only are they larger, but they're
also more pigmented, both in the petals
[SPEAKER_00]: and the filaments.
[SPEAKER_00]: This isn't necessarily a phenotype.
[SPEAKER_00]: I think this is a jointless phenotype.
[SPEAKER_00]: But yeah, I'm just showing you darker
pigmentation here and in the filaments we
[SPEAKER_00]: have anthocyanin pigmentation.
[SPEAKER_01]: Any other questions?
[SPEAKER_00]: We don't really have any other fissilis,
brosea, or prongeri accessions that I
[SPEAKER_00]: could screen.
[SPEAKER_00]: I mean, we've screened the wild type for
now that we have.
[SPEAKER_00]: And it's diploid.
[SPEAKER_00]: Our golden berry, which is also a
fissilis, is a tetraploid that we know
[SPEAKER_00]: enough people have reported on from their
chart.
[SPEAKER_00]: But I have screened other knockout lines
that I'm not showing today.
[SPEAKER_00]: I think three of them.
[SPEAKER_00]: Almost all of them were tetraploid as
well.
[SPEAKER_00]: I know other people in the lab have
generated them as well.
[SPEAKER_00]: And it's about 80% you'll get that are
tetraploid or tetraploid.
[SPEAKER_00]: So it's the highest in fissilis.
[SPEAKER_00]: I'll keep the bottle moving here.
[SPEAKER_00]: Thank you.
[SPEAKER_00]: Hello, everyone.
[SPEAKER_00]: Good afternoon.
[SPEAKER_00]: As you said, my name is Erin.
[SPEAKER_00]: I'm a third year PhD student in Mike
Gore's class.
[SPEAKER_00]: And I'm excited to talk with you all today
about integration of different
[SPEAKER_00]: proximal-remote sensors for improved
characterization of agronomically
[SPEAKER_00]: important traits such as yields.
[SPEAKER_00]: So proximal-remote sensors have
applications to both HECA's phenotype and
[SPEAKER_00]: screening programs and by researchers for
other projects as well as precision
[SPEAKER_00]: agriculture.
[SPEAKER_00]: So traditional phenotype methods are
typically time- and labor-intensive and
[SPEAKER_00]: can be too early constrained.
[SPEAKER_00]: High-throughput phenotyping, on the other
hand, may allow things like early season
[SPEAKER_00]: prediction of end-of-season traits,
thereby decreasing the time breeding
[SPEAKER_00]: cycle.
[SPEAKER_00]: It can help with phenotyping more
individuals for GWAS or training
[SPEAKER_00]: populations for genomic prediction.
[SPEAKER_00]: And being able to phenotype at a greater
temporal resolution may help understanding
[SPEAKER_00]: of genotype by environment interaction and
parameterizing crop growth model.
[SPEAKER_00]: And then for growers, the ability to
detect pests or weeds and allocate
[SPEAKER_00]: resources to different parts of the field.
[SPEAKER_00]: However, application of proximal-remote
sensors to each of these things relies on
[SPEAKER_00]: both the relevance and the accuracy.
[SPEAKER_00]: Different sensors capture different
spectra and different platforms allow
[SPEAKER_00]: selection across varying scales.
[SPEAKER_00]: So there may be unique information
contained within each of these that may
[SPEAKER_00]: increase both the relevance and accuracy
of using these sensors.
[SPEAKER_00]: However, because of the complex and
high-dimensional nature of the dots,
[SPEAKER_00]: a lot of streams collected from these
sensors, integration is uncommon into the
[SPEAKER_00]: GWAS generalizability.
[SPEAKER_00]: So I'm going to be talking about two
different platforms and sensors.
[SPEAKER_00]: First, we have multispectral images
collected by unoccupied aerial vehicles.
[SPEAKER_00]: And then we also have LIDAR scans
collected by unoccupied ground vehicles.
[SPEAKER_00]: So all of this data was collected on
genomes to field maize hybrids,
[SPEAKER_00]: planted at Musgrave Research Farm in
Aurora.
[SPEAKER_00]: And these are all two-row plots.
[SPEAKER_00]: The multispectral images you can see here
have five bands.
[SPEAKER_00]: We have blue, green, and red, which
constitute a typical image.
[SPEAKER_00]: And then we have red edge and near-red as
well.
[SPEAKER_00]: So the multispectral camera is mounted to
the bottom of the drone here.
[SPEAKER_00]: And all of the raw images have about 80%
overlap.
[SPEAKER_00]: So these are stitched together using a
software called Pix4D to create an
[SPEAKER_00]: orthomosaic.
[SPEAKER_00]: That orthomosaic is then uploaded to an
online platform called ImageFree developed
[SPEAKER_00]: in the Robbins lab to take the orthomosaic
and split it into these spot-level images
[SPEAKER_00]: here.
[SPEAKER_00]: So the LIDAR scans are collected by the
ground rover here.
[SPEAKER_00]: The LIDAR camera you can see on the back.
[SPEAKER_00]: The rover is driven in between the rows of
the two-row plots.
[SPEAKER_00]: And the LIDAR scans are converted into
three-dimensional point plots.
[SPEAKER_00]: So you can see the two rows here and some
additional points being picked up from
[SPEAKER_00]: adjacent plots, which are ultimately
propped out to give us this point plot
[SPEAKER_00]: here.
[SPEAKER_00]: Each of these points has an x,
y, and z coordinate denoting its position
[SPEAKER_00]: in space.
[SPEAKER_00]: So the LIDAR scans give us a 3D
reconstruction of each plot.
[SPEAKER_00]: So in order to achieve integration,
we're using machine learning models called
[SPEAKER_00]: autoencoders.
[SPEAKER_00]: So an autoencoder is a deep unsupervised
machine learning model, which takes its
[SPEAKER_00]: input, for example, our multispectral
image, passes it through a first neural
[SPEAKER_00]: network, the encoder, to produce what is
called the latent space here.
[SPEAKER_00]: So this latent space is reduced
representation of the original image.
[SPEAKER_00]: This latent space is then passed through a
second neural network, the decoder,
[SPEAKER_00]: which is analogous to the first to
reproduce that original image.
[SPEAKER_00]: And this model is optimized such that the
difference between the original and the
[SPEAKER_00]: reconstruction is minimized.
[SPEAKER_00]: And in that way, the latent space or the
latent phenotypes are, we hope,
[SPEAKER_00]: the important features reducing the noise
of these images.
[SPEAKER_00]: So we first trained this model on the
multispectral images, an original
[SPEAKER_00]: dimensionality of 40,000 values down to a
single vector that is 512 values.
[SPEAKER_00]: So achieving integration on these images
will involve training these models on
[SPEAKER_00]: multispectral images and, again,
on point class, extracting the latent
[SPEAKER_00]: space from each of these and concatenating
them into a single object, which can then
[SPEAKER_00]: be used for prediction.
[SPEAKER_00]: So to evaluate training of the
autoencoders, on multispectral images and
[SPEAKER_00]: the point class, which I'll show in a
moment, we looked at visualizations of the
[SPEAKER_00]: original images and the reconstruction.
[SPEAKER_00]: So you can see here that the latent space
was able to effectively reconstruct our
[SPEAKER_00]: original image.
[SPEAKER_00]: So we similarly trained the model on the
LiDAR scan.
[SPEAKER_00]: This involved a little bit or a couple of
additional pre-processing steps.
[SPEAKER_00]: So we take the original point cloud,
as you can see on the left, kind of stack
[SPEAKER_00]: the two rows together, so taking this
x-axis and flipping it, and then
[SPEAKER_00]: compressing along the time dimension here
to produce a singular single dimension
[SPEAKER_00]: density map.
[SPEAKER_00]: And, again, you can see that the latent
space contains both insufficient and
[SPEAKER_00]: necessary information to reconstruct the
high dimensional image.
[SPEAKER_00]: So the next thing that we wanted to do was
investigate these preliminary
[SPEAKER_00]: investigations of what kind of information
was contained within the latent space.
[SPEAKER_00]: So this is showing PCA plots of the 512
latent codes extracted from each of about
[SPEAKER_00]: 5,000 images, colored first by NDVI and,
again, by the date.
[SPEAKER_00]: So this is signaling that there is
biologically relevant information
[SPEAKER_00]: contained within the latent space.
[SPEAKER_00]: And, similarly, do the same thing for our
point class.
So
[SPEAKER_00]: our next steps are to take the latent
space and use them to predict ground truth
[SPEAKER_00]: phenotype.
[SPEAKER_00]: So we've done some preliminary tests of
this with Cranial, which I've not shown
[SPEAKER_00]: here, taking some simple linear models,
and Narsing's biological signal.
[SPEAKER_00]: And in particular, we are looking at
different ways to account for the temporal
[SPEAKER_00]: data that we have here.
[SPEAKER_00]: So with that, I'd like to thank my
committee.
[SPEAKER_00]: I'd like to thank Liam, Nick Lepak,
Amy Schultz, and others who helped flex
[SPEAKER_00]: all of this data.
[SPEAKER_00]: And with that, I'll take questions.
[SPEAKER_00]: You know, how do you measure that the
reconstructed image is good enough to
[SPEAKER_01]: represent your original image?
[SPEAKER_00]: That's a great question.
[SPEAKER_00]: So ultimately, we'd like to use the
prediction accuracy from that second step.
[SPEAKER_00]: So why is he changing the latent space,
using that to predict our ground truth
[SPEAKER_00]: phenotype?
[SPEAKER_00]: But, you know, initial tests would be at
the loss of the different dimensions.
[SPEAKER_00]: You know, it's possible that more blurry
or higher loss in the auto-reporter would
[SPEAKER_00]: actually need to have greater prediction
accuracy.
[SPEAKER_00]: The phenotypes left over thing of the
model.
[SPEAKER_00]: Ultimately, prediction accuracy.
[SPEAKER_01]: Amy?
[SPEAKER_01]: Are you planning on looking at,
I guess I'm curious what it comes to,
[SPEAKER_01]: incorporating this to say, well,
towards prediction model, and just to say,
[SPEAKER_01]: the drugs versus the rotors, and what are
the more beneficial models for the other,
[SPEAKER_01]: or the trillium properties of both,
that you think is going to be a bigger
[SPEAKER_00]: issue?
[SPEAKER_00]: Yeah, absolutely.
[SPEAKER_00]: So ultimately, I think that will depend on
the trade itself.
[SPEAKER_00]: But for something like, you know,
more complex like yields, or LAI,
[SPEAKER_00]: or the resources, the 3D architecture that
can be something we are hypothesizing will
[SPEAKER_00]: land additional information that will
increase that accuracy.
[SPEAKER_00]: That is something that we're planning to
test as well.
[SPEAKER_00]: So we just need the rovers, we just need
to draw and weave them together,
[SPEAKER_00]: and what is that for the process?
[SPEAKER_01]: John?
[SPEAKER_01]: Can you go back to the slide with the PCA?
[SPEAKER_01]: I guess I was struck there was that PC1
had explained 96% of the variance.
[SPEAKER_01]: So we should suggest that all of the 512
are pretty highly correlated to each
[SPEAKER_01]: other.
[SPEAKER_01]: Am I understanding that right?
[SPEAKER_01]: So why not just represent this with two
values instead of 512?
[SPEAKER_01]: I mean, like, that first PC has explained
almost everything that you have in your
[SPEAKER_01]: 512.
[SPEAKER_00]: Yeah, so I think the advantage of not
using PCA would be you don't have that
[SPEAKER_00]: linearity constraint.
[SPEAKER_00]: On the looking at the relationship between
the different values.
[SPEAKER_00]: The, you know, one potential reason that
that first value is so high is to really
[SPEAKER_00]: have it related with the date or
something.
[SPEAKER_00]: So you're really able to figure out the
brightness level.
[SPEAKER_00]: So even though that first PC has a high
percentage, it might be something that's
[SPEAKER_00]: not biologically relevant.
[SPEAKER_01]: If you did the auto-reporter process,
I'm just pointing dates.
[SPEAKER_01]: So that date isn't a factor of positive
variation.
[SPEAKER_01]: What would it look like?
[SPEAKER_01]: Maybe something is swapped by date in
other words.
[SPEAKER_00]: Yeah, that's not cool.
[SPEAKER_00]: I don't think that's what I need to do.
[SPEAKER_00]: Yeah, so from below, you're going to get
three reconstructions of the years
[SPEAKER_00]: themselves.
[SPEAKER_00]: For example, where it's from above,
particularly later days when that can be
[SPEAKER_00]: closure that you're not going to be able
to pick up on that.
[SPEAKER_00]: Yeah, other things below can't be that
when you have that closure you're not
[SPEAKER_01]: reaching.
[SPEAKER_00]: Yeah, that's a great point.
[SPEAKER_00]: Something that we have talked about doing
but not doing that is introducing,
[SPEAKER_00]: you know, like a secondary law function
for a genotype or, you know, spatial
[SPEAKER_00]: location in the field.
[SPEAKER_01]: In other words, you want the decoder to
generate something that resembles the
[SPEAKER_01]: other replicate.
[SPEAKER_01]: Right, yeah.
[SPEAKER_01]: You can also do this by running the rotors
going off the direction on the rows and
[SPEAKER_01]: other side of the rows.
[SPEAKER_01]: So that's the other thing you can do.
[SPEAKER_01]: They're trying to run it on one side and
then try to do it on the other side.
[SPEAKER_00]: Yeah, thank you.
[SPEAKER_00]: Yeah, I don't think I'm trying.
[SPEAKER_02]: Yeah, thank you.
[SPEAKER_02]: This has been a production of Cornell
University on the web at Cornell.edu.
[SPEAKER_02]: Thank you.
[SPEAKER_02]: Thank you.
you
