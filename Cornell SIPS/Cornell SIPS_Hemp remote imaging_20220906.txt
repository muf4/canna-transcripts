[00:00.000 --> 00:02.560]  This is a production of Cornell University.
[00:08.880 --> 00:11.720]  The first is one of my graduate students,
[00:11.720 --> 00:14.760]  PhD student in plant breeding, Maylin Murdoch,
[00:14.760 --> 00:19.760]  and the focus of her research, remote sensing,
[00:21.280 --> 00:24.260]  mainly for phenotyping in our breeding program,
[00:24.260 --> 00:27.120]  but also eventually perhaps for crop management.
[00:28.300 --> 00:30.540]  But what we have done here at this stop
[00:30.540 --> 00:33.180]  is built in a lot of free time,
[00:33.180 --> 00:36.140]  because in this trial here,
[00:36.140 --> 00:38.640]  there is quite a bit of genetic variability,
[00:39.700 --> 00:42.540]  and we wanted to give you the opportunity
[00:42.540 --> 00:46.700]  to walk through the field and see the phenotypic differences
[00:46.700 --> 00:48.140]  and ask us questions.
[00:49.420 --> 00:52.660]  So with no further ado, I will pass the mic to May.
[00:53.900 --> 00:55.620]  Thank you, Larry.
[00:55.620 --> 00:57.620]  As Larry said, my name is Maylin Murdoch.
[00:57.620 --> 01:01.180]  I'm a first year, going into my second year PhD student.
[01:01.180 --> 01:02.940]  The interest in digital agriculture,
[01:02.940 --> 01:05.100]  specifically remote sensing,
[01:05.100 --> 01:07.900]  as it applies to hemp breeding and production systems.
[01:07.900 --> 01:12.140]  And there is an additional speaker today, Kathleen.
[01:12.140 --> 01:14.180]  I'll let her introduce herself.
[01:14.180 --> 01:15.660]  Hi, I am not working in hemp.
[01:15.660 --> 01:18.120]  My name is Kathleen and I work with grapes,
[01:18.120 --> 01:21.760]  but May and I are doing very related sort of investigations
[01:21.760 --> 01:23.140]  and using similar tools.
[01:24.140 --> 01:27.700]  So how we'd like to kind of organize this,
[01:27.700 --> 01:29.580]  we're gonna do a brief introduction
[01:29.580 --> 01:32.460]  and then we're gonna split into two groups.
[01:32.460 --> 01:34.700]  One group will be in the field with me
[01:34.700 --> 01:37.340]  and another group would be here with Kathleen,
[01:37.340 --> 01:39.800]  kind of talking about sensors and applications
[01:39.800 --> 01:42.340]  and give you guys more chances
[01:42.340 --> 01:44.180]  to really ask your questions
[01:44.180 --> 01:46.240]  about remote sensing applications.
[01:47.220 --> 01:49.380]  So just a quick show of hands,
[01:49.380 --> 01:53.080]  how many are familiar with the term remote sensing?
[01:54.940 --> 01:55.940]  We love this.
[01:55.940 --> 01:58.900]  How many are familiar with the,
[01:59.980 --> 02:02.040]  drones and use of drones for agriculture?
[02:03.340 --> 02:04.460]  Okay, nice.
[02:04.460 --> 02:06.980]  Well, then I'll give a brief kind of overview
[02:06.980 --> 02:11.980]  what it means to remote sense and our aims and goals here.
[02:12.660 --> 02:14.980]  So essentially remote sensing
[02:14.980 --> 02:17.560]  is learning and collecting information
[02:17.560 --> 02:18.680]  about the earth's surface
[02:18.680 --> 02:21.080]  without being in contact to it specifically.
[02:21.080 --> 02:23.920]  I'm interested in hemp, Kathleen, grapes,
[02:25.400 --> 02:28.000]  and we utilize drones on a week to week,
[02:28.000 --> 02:31.280]  honestly daily basis besides the weekends.
[02:31.280 --> 02:35.240]  And we've been doing this the entire summer almost,
[02:35.240 --> 02:38.000]  I think trying to figure out
[02:38.000 --> 02:41.480]  how to best acquire digital traits
[02:41.480 --> 02:45.600]  and correlate them with what we see in the field
[02:45.600 --> 02:47.920]  with our eyes on a day to day basis.
[02:47.920 --> 02:50.760]  So our aim with remote sensing
[02:50.760 --> 02:54.720]  is essentially to kind of bridge the gaps
[02:54.720 --> 02:59.040]  with genetic improvements.
[02:59.040 --> 03:00.600]  We can do a lot genetically now,
[03:00.600 --> 03:03.480]  but there's not a lot we can do phenotypically
[03:03.480 --> 03:07.520]  unless you have a large or big team with you, right?
[03:07.520 --> 03:09.400]  And I know many growers and farmers
[03:09.400 --> 03:12.020]  have larger acreages of this than we have.
[03:12.020 --> 03:15.120]  So really we hope to improve the status
[03:15.640 --> 03:17.920]  of how can you collect phenotypical data
[03:17.920 --> 03:20.660]  and how can you do that at a high throughput.
[03:22.480 --> 03:25.840]  So we're gonna split into two groups.
[03:25.840 --> 03:26.760]  The group that will be me
[03:26.760 --> 03:29.320]  will go and talk about this field trial.
[03:29.320 --> 03:30.800]  And then the group that will be here
[03:30.800 --> 03:32.960]  will talk about sensors and applications.
[03:32.960 --> 03:36.080]  Two different drones that do two different things.
[03:36.080 --> 03:39.540]  So right over here, this is called the M100
[03:39.540 --> 03:42.440]  and this guy has two cameras on it.
[03:42.440 --> 03:44.380]  So there's the white one over here,
[03:44.380 --> 03:45.900]  that's a near infrared camera.
[03:45.900 --> 03:49.180]  And those are wavelengths that we as humans don't pick up,
[03:49.180 --> 03:51.220]  but they're just outside the visible range.
[03:51.220 --> 03:54.660]  And they're great for monitoring things like plant health
[03:54.660 --> 03:56.240]  because they give you a lot of information
[03:56.240 --> 03:58.840]  about the structure of different leaves.
[03:58.840 --> 04:02.400]  So when really any type of stress is affecting a plant
[04:02.400 --> 04:03.980]  and the leaves either start to wilt
[04:03.980 --> 04:05.940]  or maybe looking a little bit yellower,
[04:05.940 --> 04:07.860]  the near infrared is really sensitive to that.
[04:07.860 --> 04:11.100]  So that's the reason why that added camera is there.
[04:11.100 --> 04:13.340]  And then the red, green, blue camera is,
[04:13.340 --> 04:15.220]  there's a little red device under there.
[04:15.220 --> 04:16.980]  So that's what's on this drone.
[04:16.980 --> 04:18.740]  And as you can tell, this is smaller, right?
[04:18.740 --> 04:21.020]  So it's a lot more lightweight.
[04:21.020 --> 04:24.460]  It can go a lot further and be in the air for longer
[04:24.460 --> 04:26.620]  because it's not carrying as much.
[04:26.620 --> 04:30.420]  This is the M600, obviously a lot bigger.
[04:30.420 --> 04:33.460]  And this has two sensors on it.
[04:33.460 --> 04:36.980]  One of them is this camera down here
[04:36.980 --> 04:40.340]  and that actually does 10 different wave bands.
[04:40.340 --> 04:42.400]  So you've got red, green, blue,
[04:42.440 --> 04:46.520]  but you've also got finer gradations within that spectrum.
[04:46.520 --> 04:48.200]  And that's again, really helpful
[04:48.200 --> 04:51.460]  because not only are we getting things
[04:51.460 --> 04:53.440]  that we could pick up if we were in the air,
[04:53.440 --> 04:55.040]  but we also get more information
[04:55.040 --> 04:57.520]  from different ranges of the electromagnetic spectrum
[04:57.520 --> 04:59.200]  that we can't see.
[05:00.320 --> 05:02.480]  There's also a thermal camera on this one
[05:02.480 --> 05:04.660]  and that gives obviously information about temperature.
[05:04.660 --> 05:07.080]  So as many of you guys probably know,
[05:07.080 --> 05:09.080]  evapotranspiration and stomatal conductance
[05:09.080 --> 05:11.160]  are two metrics that can tell us a lot
[05:11.160 --> 05:14.200]  about what's happening in a particular plant
[05:14.200 --> 05:16.880]  and being able to see that from up high
[05:16.880 --> 05:19.840]  and see maybe areas where your plants
[05:19.840 --> 05:23.480]  are looking a lot hotter in one particular part of the field
[05:23.480 --> 05:25.400]  than another could be really informative,
[05:25.400 --> 05:27.760]  especially when we're thinking about things like irrigation,
[05:27.760 --> 05:31.160]  water stress, and also for some diseases.
[05:31.160 --> 05:33.840]  So these are the two tools that we are using
[05:33.840 --> 05:36.680]  and May and I primarily actually have been flying
[05:36.680 --> 05:39.620]  the M600 this summer to get a little bit finer detail.
[05:40.020 --> 05:44.100]  When we go out with these drones,
[05:44.100 --> 05:45.900]  there are a couple of steps that are required
[05:45.900 --> 05:47.540]  to make a flight happen.
[05:47.540 --> 05:50.100]  So one of those is the flight plan.
[05:50.100 --> 05:52.740]  We are not, because we're using this for data collection,
[05:52.740 --> 05:55.520]  we want things to be pretty consistent.
[05:55.520 --> 05:58.140]  We have a flight plan that's the same every week.
[05:58.140 --> 06:01.540]  So we're not manually flying this over this field.
[06:01.540 --> 06:04.220]  It's a pre-programmed flight that we set up
[06:04.220 --> 06:06.000]  and that ensures that the drone will follow
[06:06.000 --> 06:07.860]  the exact same path every week
[06:07.900 --> 06:10.260]  so that we have consistency over time.
[06:11.140 --> 06:12.980]  We can obviously fly it manually
[06:12.980 --> 06:14.500]  if something were to occur and go wrong
[06:14.500 --> 06:16.300]  and we needed to switch that up.
[06:16.300 --> 06:19.100]  And that's what the remote control here is for.
[06:19.100 --> 06:22.140]  And so this little stand is where you would put
[06:22.140 --> 06:25.100]  a smartphone, a tablet, so you could sort of
[06:25.100 --> 06:27.700]  see your path on the phone
[06:27.700 --> 06:30.260]  and that's where you would also be able to do things
[06:30.260 --> 06:33.320]  like land it automatically if you wanted to.
[06:33.320 --> 06:37.800]  And then the joysticks are for the actual manual flight.
[06:39.500 --> 06:41.880]  And as an example, you can see the flight plan
[06:41.880 --> 06:43.740]  that we have for this field up here.
[06:43.740 --> 06:46.480]  And you guys feel free to come closer if you want.
[06:46.480 --> 06:50.320]  But it's a pretty standard sort of area scan.
[06:50.320 --> 06:51.840]  So it's a rectangular back and forth
[06:51.840 --> 06:53.640]  and back and forth and back and forth.
[06:53.640 --> 06:55.020]  And you can switch things, right?
[06:55.020 --> 06:58.760]  Like you can make it fly lower, you can make it fly higher,
[06:58.760 --> 07:00.520]  you can tighten up the interval
[07:00.520 --> 07:03.680]  between those consecutive paths over the field
[07:03.680 --> 07:06.960]  if you want to have many, many overlapping images.
[07:08.600 --> 07:11.960]  Any questions about any of this thus far?
[07:11.960 --> 07:12.800]  Or no, I bet.
[07:12.800 --> 07:14.080]  So when you collect data,
[07:14.080 --> 07:18.280]  you're collecting digital images.
[07:18.280 --> 07:20.800]  And you see, you suspect that there's something
[07:20.800 --> 07:24.520]  that's happening there, a pest infestation, something.
[07:24.520 --> 07:28.560]  How do you corroborate that or validate that on the ground?
[07:28.560 --> 07:29.480]  That's a really good question.
[07:29.480 --> 07:32.520]  So May and I have a slightly different projects.
[07:32.520 --> 07:34.400]  I'm working with disease.
[07:34.400 --> 07:37.020]  And so for us, ground truthing corroboration
[07:37.020 --> 07:40.480]  looks like weekly scouting in, for me, it's a vineyard.
[07:40.480 --> 07:44.160]  But so every week on the same day that the drone flies,
[07:44.160 --> 07:46.920]  we go out and we look at every single vine and we say,
[07:46.920 --> 07:50.400]  okay, on this vine, this is our percentage of infection.
[07:50.400 --> 07:52.040]  And then at the end of the season,
[07:52.040 --> 07:54.640]  take those digital images from that particular day
[07:54.640 --> 07:57.560]  and say, all right, this is what we got from the image,
[07:57.560 --> 07:59.280]  whether that's a vegetation index
[08:00.040 --> 08:01.200]  or whether that's a specific band
[08:01.200 --> 08:03.280]  and see what's the relationship between that index
[08:03.280 --> 08:05.660]  or between the value of that band
[08:05.660 --> 08:07.600]  and the level of disease we saw.
[08:07.600 --> 08:10.000]  May is using it for something slightly different
[08:10.000 --> 08:12.240]  because she's looking at sort of different traits
[08:12.240 --> 08:16.660]  and differentiating between different types of hemp plants.
[08:16.660 --> 08:20.200]  So her ground truthing is actually a lot more extensive.
[08:20.200 --> 08:23.360]  So they're taking things like heights, like leaf diameter.
[08:23.360 --> 08:24.880]  They've been doing, I guess we've both been doing
[08:24.880 --> 08:27.520]  stomatal conductance, but for different reasons.
[08:28.400 --> 08:30.840]  So it depends what you're, right,
[08:30.840 --> 08:32.560]  what you wanna use the digital imagery for
[08:32.560 --> 08:35.280]  will determine the measurements you take on the ground
[08:35.280 --> 08:36.760]  to validate that.
[08:36.760 --> 08:38.560]  But that is a really critical piece of this
[08:38.560 --> 08:42.080]  because at the end of the day, this will give you a picture.
[08:42.080 --> 08:43.520]  That picture is pretty much useless
[08:43.520 --> 08:46.120]  unless you know something about what was happening
[08:46.120 --> 08:48.020]  on the ground at that particular time.
[08:49.340 --> 08:53.240]  So are these going to be made available to farmers?
[08:53.240 --> 08:57.880]  So the idea is at least right now,
[08:57.880 --> 08:59.280]  we're interested in figuring out
[08:59.280 --> 09:00.680]  what are those relationships?
[09:00.680 --> 09:04.680]  And if a farmer does have a drone and has images,
[09:04.680 --> 09:07.480]  sort of turning that image into information
[09:07.480 --> 09:10.480]  and making that a very seamless process.
[09:11.720 --> 09:15.680]  These can range in cost, as you might imagine,
[09:15.680 --> 09:18.800]  from like hundreds of dollars to thousands of dollars.
[09:18.800 --> 09:22.920]  So the model for application on a given farm
[09:23.600 --> 09:26.280]  will probably look very different from place to place.
[09:26.280 --> 09:28.360]  One of the things that I think would be really amazing
[09:28.360 --> 09:31.400]  is if there was sort of like a central service, right?
[09:31.400 --> 09:33.240]  Okay, there's the drone team.
[09:33.240 --> 09:34.840]  I want my field scanned.
[09:34.840 --> 09:38.920]  I call this person, the scan happens,
[09:38.920 --> 09:42.720]  and then I get basically a map of either crop health
[09:42.720 --> 09:45.800]  or maybe heights or biomass or whatever it is
[09:45.800 --> 09:47.000]  that I'm interested in.
[09:47.000 --> 09:48.640]  You've just become the entrepreneur.
[09:48.640 --> 09:49.480]  There you go.
[09:49.480 --> 09:50.320]  There you go.
[09:50.320 --> 09:51.140]  You need to do that.
[09:51.940 --> 09:53.900]  That's not, obviously, I'm a PhD student.
[09:53.900 --> 09:54.780]  That's not what I'm here for,
[09:54.780 --> 09:56.980]  but that's like something that is interesting
[09:56.980 --> 09:57.820]  to think about, right?
[09:57.820 --> 10:01.540]  Is okay, what is, and that's kind of why I got into this
[10:01.540 --> 10:02.740]  in the first place with, yeah,
[10:02.740 --> 10:06.420]  how do we bring this to an actual farm?
[10:06.420 --> 10:07.260]  And what would that look like?
[10:07.260 --> 10:10.220]  So eventually the user would not actually have to do
[10:10.220 --> 10:12.180]  his or her own ground truthing.
[10:12.180 --> 10:13.420]  Yep, exactly.
[10:13.420 --> 10:16.300]  And I think there, I mean, yes and no, right?
[10:16.300 --> 10:18.460]  This will never replace a person.
[10:18.500 --> 10:20.940]  This is never gonna be smarter than a human,
[10:21.820 --> 10:24.540]  but the idea would be that, for example,
[10:24.540 --> 10:27.580]  if you have hundreds of acres to manage
[10:27.580 --> 10:31.300]  and you're concerned about a particular pest
[10:31.300 --> 10:34.580]  or a particular disease,
[10:34.580 --> 10:37.640]  having an idea of this is where I wanna look first
[10:37.640 --> 10:40.500]  because I know based on my images
[10:40.500 --> 10:42.940]  that this particular quadrant of the field
[10:42.940 --> 10:45.540]  is looking a lot more stressed out than everywhere else.
[10:45.540 --> 10:48.900]  And maybe that's where to sort of begin that process of,
[10:48.900 --> 10:52.020]  okay, I wanna focus here, see what's going on
[10:52.020 --> 10:53.340]  and manage accordingly.
[10:55.140 --> 10:56.600]  So not as a replacement, I would say,
[10:56.600 --> 10:59.140]  but more so as a compliment, as a tool
[11:00.320 --> 11:01.980]  to make this a little bit easier.
[11:03.100 --> 11:04.580]  You mentioned a flight plan.
[11:04.580 --> 11:07.740]  So do you have to have a pilot's license?
[11:07.740 --> 11:09.580]  You do have to have a pilot's license
[11:10.460 --> 11:15.460]  and it's relatively almost scarily easy to obtain one.
[11:16.100 --> 11:18.820]  You don't have to prove that you can fly it.
[11:18.820 --> 11:20.980]  You just have to know the rules about,
[11:20.980 --> 11:23.060]  okay, where are you allowed to fly a drone
[11:23.060 --> 11:24.740]  and where are you not allowed to fly a drone
[11:24.740 --> 11:26.820]  and sort of things taken into account
[11:26.820 --> 11:28.660]  as far as like air conditions.
[11:30.780 --> 11:32.100]  Most of it is safety.
[11:32.100 --> 11:33.820]  It's a bit like getting a permit
[11:33.820 --> 11:35.740]  before you get your driver's license,
[11:36.780 --> 11:39.060]  but it's administered through the FAA.
[11:39.060 --> 11:42.100]  You can prepare for the exam online, take it.
[11:42.100 --> 11:43.900]  There are testing centers all over the country.
[11:44.060 --> 11:47.380]  So it's, yeah, actually the licensing process
[11:47.380 --> 11:49.380]  is quite straightforward.
[11:50.220 --> 11:53.380]  A large grape producer, a large fruit producer
[11:53.380 --> 11:56.980]  could certainly be able to afford their own drone.
[11:56.980 --> 11:58.020]  Yeah, absolutely.
[11:58.020 --> 11:59.860]  To monitor their own crops.
[11:59.860 --> 12:02.220]  Yep, and the software to make these flight plans
[12:02.220 --> 12:05.020]  is also very easy to obtain.
[12:06.120 --> 12:07.100]  I think the biggest, I don't know,
[12:07.100 --> 12:10.380]  the biggest sort of missing piece
[12:10.380 --> 12:14.020]  would be that turning the images right into information.
[12:14.020 --> 12:17.820]  That I think is the part that we're trying to make simpler
[12:17.820 --> 12:19.980]  and much faster than it is right now.
[12:23.180 --> 12:27.300]  How stable are they with updrafts or down drafts?
[12:27.300 --> 12:31.980]  Yeah, they are below certain wind speeds.
[12:31.980 --> 12:33.100]  They're very, very stable.
[12:33.100 --> 12:36.420]  So we cannot fly this with wind speeds
[12:36.420 --> 12:37.740]  above 12 miles an hour.
[12:37.780 --> 12:40.660]  It would not be advisable.
[12:40.660 --> 12:42.500]  But that being said, I mean,
[12:42.500 --> 12:44.300]  when wind speeds are under 12 miles an hour,
[12:44.300 --> 12:45.340]  it's really, really stable.
[12:45.340 --> 12:48.540]  So you don't see it up there shaking around.
[12:50.780 --> 12:52.060]  This, we're looking at,
[12:52.060 --> 12:54.220]  we're right about there actually right now.
[12:56.100 --> 12:57.940]  Yeah, I do check this every morning.
[12:59.300 --> 13:04.300]  We are at, yeah, let's see what we got.
[13:04.460 --> 13:05.300]  Gusts.
[13:06.140 --> 13:08.660]  Yeah, we've got average eight gusts of 18.
[13:12.380 --> 13:14.980]  What's your battery like on the two?
[13:14.980 --> 13:16.100]  Yeah, good question.
[13:16.100 --> 13:18.820]  So this one takes six batteries
[13:18.820 --> 13:21.220]  and these are the little slots where they go in.
[13:21.220 --> 13:26.220]  That will get us about 23 total minutes of flight time.
[13:27.180 --> 13:29.420]  So it takes, when we scan this field,
[13:29.420 --> 13:31.900]  that's about a seven minute scan.
[13:31.900 --> 13:35.580]  So we could do that, three times we'd be pushing it,
[13:35.580 --> 13:37.660]  but we could do that three times.
[13:37.660 --> 13:39.300]  And again, like the length of your scan
[13:39.300 --> 13:40.780]  depends on how high you're flying,
[13:40.780 --> 13:43.420]  how many times you wanna pass over.
[13:44.460 --> 13:45.300]  But yeah.
[13:45.300 --> 13:46.420]  So wind speed.
[13:46.420 --> 13:48.780]  So wind speed does impact that, yeah.
[13:48.780 --> 13:50.660]  How fast does it travel?
[13:50.660 --> 13:51.620]  You can set that.
[13:51.620 --> 13:53.380]  We, for scans like this,
[13:53.380 --> 13:54.980]  we set it at two meters per second
[13:54.980 --> 13:56.580]  or three meters per second,
[13:56.580 --> 13:57.540]  but you could fly it.
[13:57.540 --> 13:59.420]  I mean, you probably wouldn't,
[13:59.420 --> 14:03.500]  I wouldn't wanna fly it over five meters per second,
[14:03.500 --> 14:05.340]  but you could, you definitely could.
[14:05.340 --> 14:07.340]  I would still get the same information.
[14:07.340 --> 14:09.180]  You'd get the same, well, you get the same information,
[14:09.180 --> 14:12.420]  but you might not get the best quality of images
[14:12.420 --> 14:13.660]  because you would get sort of,
[14:13.660 --> 14:16.300]  imagine it's flying quicker.
[14:16.300 --> 14:17.340]  So the captures,
[14:17.340 --> 14:19.740]  even if you're capturing at the same rate,
[14:19.740 --> 14:22.500]  you might not get as much overlap between your images.
[14:22.500 --> 14:25.460]  So you could have perhaps one image
[14:25.460 --> 14:28.660]  of the same sort of footprint on the ground.
[14:28.660 --> 14:31.500]  Whereas when we fly it at a lower speed,
[14:31.500 --> 14:34.420]  you would get maybe three overlapping images
[14:34.420 --> 14:35.300]  of that same area.
[14:35.300 --> 14:37.380]  So if one image is a little bit off,
[14:37.380 --> 14:38.980]  you would have sort of a backup.
[14:40.380 --> 14:42.420]  How long is that one gonna last?
[14:42.420 --> 14:43.260]  This guy,
[14:45.020 --> 14:45.860]  I think you would,
[14:45.860 --> 14:48.780]  we could probably get 35 on a set of batteries.
[14:48.780 --> 14:50.020]  Yeah.
[14:50.020 --> 14:51.180]  Yeah.
[14:51.180 --> 14:52.020]  Yeah.
[14:52.020 --> 14:52.860]  So.
[14:52.860 --> 14:55.500]  And what's the cost of that bigger one there?
[14:55.500 --> 14:58.620]  This, with no cameras,
[14:59.460 --> 15:00.300]  and actually it's funny,
[15:00.300 --> 15:02.180]  the cameras are usually the more expensive piece,
[15:02.180 --> 15:03.540]  but no cameras.
[15:05.020 --> 15:09.460]  I wanna say that one comes in around 10 grand.
[15:09.460 --> 15:10.300]  Yeah.
[15:10.300 --> 15:11.580]  Yeah.
[15:11.580 --> 15:12.460]  Without the camera?
[15:12.460 --> 15:13.580]  Without the camera.
[15:13.580 --> 15:15.060]  And with the cameras?
[15:15.060 --> 15:16.380]  With the cameras,
[15:16.380 --> 15:17.620]  I'm gonna be honest,
[15:17.620 --> 15:20.380]  I don't know how much these cameras cost.
[15:20.380 --> 15:21.620]  I didn't wanna ask.
[15:21.620 --> 15:22.460]  But yeah.
[15:22.460 --> 15:23.900]  How about that guy?
[15:23.900 --> 15:25.980]  This one, much, much less.
[15:26.020 --> 15:29.420]  So I think probably about half as much for that one,
[15:29.420 --> 15:30.740]  if that, yeah.
[15:30.740 --> 15:31.580]  Without the camera?
[15:31.580 --> 15:32.580]  Without the camera.
[15:33.620 --> 15:34.700]  So how is the,
[15:34.700 --> 15:37.380]  how do you identify the image or plants?
[15:37.380 --> 15:39.100]  Are they, are you,
[15:39.100 --> 15:40.580]  you have stakes,
[15:40.580 --> 15:42.340]  tags out there, or coordinates?
[15:42.340 --> 15:43.180]  It depends, yeah,
[15:43.180 --> 15:44.540]  it depends on the field.
[15:44.540 --> 15:48.060]  What we do for grapes is we have,
[15:48.060 --> 15:50.340]  we basically went out and we took the location
[15:50.340 --> 15:52.020]  of each post that's in the vineyard,
[15:52.020 --> 15:53.300]  and so we know, okay,
[15:53.300 --> 15:55.260]  we have those points, right,
[15:55.300 --> 15:57.140]  in the image where we know the posts are.
[15:57.140 --> 15:59.220]  So in between those points,
[15:59.220 --> 16:00.820]  within a certain width,
[16:00.820 --> 16:02.380]  that's our vine.
[16:03.580 --> 16:05.180]  For things like hemp,
[16:05.180 --> 16:06.580]  like for this field,
[16:06.580 --> 16:07.740]  from the picture,
[16:07.740 --> 16:11.420]  you see very clearly where the individual plants are,
[16:11.420 --> 16:14.220]  but there is a bit of manual work
[16:14.220 --> 16:16.460]  that goes into sort of segmenting out.
[16:16.460 --> 16:18.540]  But this is kind of a small,
[16:18.540 --> 16:19.380]  Small.
[16:19.380 --> 16:20.220]  Yeah.
[16:20.220 --> 16:21.060]  And a large one.
[16:21.060 --> 16:21.900]  And that, well, yeah,
[16:21.900 --> 16:24.020]  and that's a huge challenge to image processing,
[16:24.020 --> 16:27.980]  is quickly obtaining only the areas that you want, right?
[16:27.980 --> 16:30.140]  If you don't care about the tarp,
[16:30.140 --> 16:31.740]  you don't want to be analyzing the tarp,
[16:31.740 --> 16:35.540]  but segmenting out the parts that you care about,
[16:35.540 --> 16:37.260]  that's a challenge for sure.
[16:37.260 --> 16:38.540]  Yeah.
[16:38.540 --> 16:40.460]  Now, do you have a program that processes the images
[16:40.460 --> 16:41.300]  to kind of give you like,
[16:41.300 --> 16:42.140]  or do you have to make?
[16:42.140 --> 16:43.860]  To a certain extent, yes,
[16:43.860 --> 16:45.180]  but the segmentation piece,
[16:45.180 --> 16:47.740]  that's something that we're working on to automate that.
[16:47.740 --> 16:49.660]  That does not exist yet,
[16:49.660 --> 16:51.420]  and we're hoping to build that,
[16:51.420 --> 16:52.340]  so that you could write,
[16:52.340 --> 16:54.580]  or you could feasibly scan a hundred acres,
[16:54.580 --> 16:57.300]  and then say, okay, of that hundred acres,
[16:57.300 --> 16:58.980]  I want to look at only the pixels
[16:58.980 --> 17:00.220]  that correspond to my crop,
[17:00.220 --> 17:03.180]  and not the weeds, not the dirt, nothing else.
[17:05.680 --> 17:09.420]  You mentioned that your area is diseased,
[17:09.420 --> 17:11.420]  and you can also tell from the imagery,
[17:11.420 --> 17:13.900]  if the vines are being drought stressed,
[17:13.900 --> 17:16.940]  or stressed for other reasons.
[17:16.940 --> 17:20.060]  Could also use in spring to see,
[17:20.900 --> 17:22.660]  if there is freeze death,
[17:22.660 --> 17:25.540]  so if you wait when the vines are coming out of dormancy,
[17:25.540 --> 17:28.460]  and fly it, then you can see how many vines
[17:28.460 --> 17:31.180]  are not producing any.
[17:31.180 --> 17:33.500]  Yeah, yeah, that's a really good question,
[17:33.500 --> 17:35.500]  and we're working on that right now,
[17:35.500 --> 17:40.340]  not with drones, but with proximal sensors,
[17:40.340 --> 17:42.140]  that you actually mount on a tractor,
[17:42.140 --> 17:43.780]  and so there are cameras that you would mount on the tractor,
[17:43.780 --> 17:45.020]  and you'd go through the vineyard,
[17:45.020 --> 17:47.340]  and they take, yeah, they take images
[17:47.340 --> 17:49.140]  of each side of the tractor,
[17:49.180 --> 17:51.060]  so each row, and with that,
[17:51.060 --> 17:52.740]  you get readings from the canopy,
[17:52.740 --> 17:55.420]  so you can tell exactly when everything
[17:55.420 --> 17:58.180]  is starting to push out shoots,
[17:58.180 --> 18:00.340]  okay, if there was a lot of winter kill,
[18:00.340 --> 18:01.740]  there are some plants that you're not gonna see
[18:01.740 --> 18:04.500]  any green whatsoever, and that will come out,
[18:04.500 --> 18:06.260]  so that's one of the applications that we're looking at,
[18:06.260 --> 18:07.480]  to kind of get a better sense,
[18:07.480 --> 18:08.740]  at the very beginning of the season,
[18:08.740 --> 18:11.580]  okay, how much winter damage is there,
[18:11.580 --> 18:15.260]  and is there anything that we can do with pruning
[18:15.260 --> 18:19.140]  to make sure that there's a decent crop load?
[18:22.420 --> 18:24.420]  And where could I look up information
[18:24.420 --> 18:27.020]  on those sensors to mount on a four-wheeler,
[18:27.020 --> 18:30.060]  or side by side, where could I look for that?
[18:30.060 --> 18:32.460]  Yeah, there is, if you look,
[18:32.460 --> 18:34.540]  so there's a company called CropScape,
[18:34.540 --> 18:38.620]  that has the sensors that we've been using for grapes,
[18:38.620 --> 18:41.900]  and for, I mean, for the drones,
[18:42.420 --> 18:46.220]  I would say DJI, so the letter is DJI,
[18:46.220 --> 18:48.580]  that's the company that manufactures these two,
[18:48.580 --> 18:51.660]  and is probably, at this point,
[18:51.660 --> 18:54.340]  one of the better, I guess, better known,
[18:54.340 --> 18:57.140]  but also higher quality, for research purposes,
[18:57.140 --> 18:58.800]  manufacturers of drones,
[18:59.940 --> 19:03.780]  and they have a lot of sort of options,
[19:03.780 --> 19:06.220]  as far as pieces of equipment and sensors.
[19:06.220 --> 19:07.060]  So.
[19:08.860 --> 19:11.340]  So you could get a used drone, probably, much cheaper.
[19:11.340 --> 19:13.860]  I bet you could, yeah, 100%.
[19:13.860 --> 19:16.340]  And that's not, by any means, the only company,
[19:16.340 --> 19:20.620]  like there are many that are equally good,
[19:20.620 --> 19:22.820]  as far as quality goes.
[19:22.820 --> 19:26.540]  I think it's more about learning, on the user side,
[19:26.540 --> 19:30.220]  making sure that the person is comfortable with flying it.
[19:31.860 --> 19:34.660]  So I'm sure you guys had a lot of great conversations
[19:34.660 --> 19:35.620]  with Kathleen over there,
[19:35.620 --> 19:37.500]  learning about sensors and applications,
[19:37.500 --> 19:38.740]  and you're definitely more than welcome
[19:38.740 --> 19:40.180]  to ask me a bit about it.
[19:40.180 --> 19:41.740]  Last session, we kind of got drifted away
[19:41.740 --> 19:44.300]  in talking about seeds and seeds companies,
[19:44.300 --> 19:46.340]  so we'll try to keep this one more specific
[19:46.340 --> 19:48.080]  to remote sensing.
[19:49.820 --> 19:52.020]  So like I said, our aim,
[19:52.020 --> 19:53.980]  Cornell Hemp's aim with remote sensing,
[19:53.980 --> 19:57.700]  it's really, you know, this is kind of a foundational trial
[19:57.700 --> 19:59.860]  for the remote sensing efforts with Cornell Hemp,
[19:59.860 --> 20:02.620]  and I'm only in my second year now,
[20:02.620 --> 20:06.100]  so I'm really hoping to kind of refine this
[20:06.100 --> 20:07.360]  in my later years.
[20:08.340 --> 20:11.220]  But this is our, you're sitting, you're standing, really,
[20:11.220 --> 20:12.580]  in our wide space trial,
[20:12.580 --> 20:15.860]  and this wide space trial has four different populations.
[20:18.180 --> 20:21.860]  Two are quote, quote, cultivars.
[20:21.860 --> 20:24.820]  You can see very quickly that this is not uniform,
[20:24.820 --> 20:27.600]  and to be a cultivar, you need to be uniform.
[20:28.540 --> 20:30.060]  And then the last two down there,
[20:30.060 --> 20:32.180]  which we'll go over in the next session with Jacob,
[20:32.700 --> 20:36.260]  are some of our own Cornell Hemp produced populations.
[20:36.260 --> 20:39.620]  So yeah, what I mean by wide space
[20:39.620 --> 20:41.740]  is seven and a half feet by seven and a half feet.
[20:41.740 --> 20:44.780]  You'll notice that we have black weed fabric here,
[20:44.780 --> 20:46.840]  and we have beds with black tarp.
[20:46.840 --> 20:49.480]  This really helps me in my remote sensing efforts.
[20:49.480 --> 20:54.180]  Like I said, we do weekly, daily flights, really,
[20:55.500 --> 20:57.600]  and a lot of ground-truthing measurements.
[20:57.600 --> 21:00.700]  So this kind of helps keep the weeds away
[21:00.740 --> 21:05.400]  and really pinpoint the plant of interest that we need.
[21:06.460 --> 21:08.880]  So our goal with this trial specifically
[21:08.880 --> 21:13.100]  is plant architecture, growth stages, and yield estimation.
[21:13.100 --> 21:14.620]  It's been done in a lot of crops,
[21:14.620 --> 21:16.940]  and this one has had a lot of literature supporting.
[21:16.940 --> 21:20.480]  So now we just need to, all we need to do, right,
[21:20.480 --> 21:23.400]  is kind of make those studies happen,
[21:23.400 --> 21:26.020]  then have a good model for prediction
[21:26.020 --> 21:28.120]  for farmers and growers to use.
[21:29.120 --> 21:32.080]  So in that, our specific goals here
[21:32.080 --> 21:35.360]  are extensive phenotyping, like I said.
[21:35.360 --> 21:38.520]  Me and the rest of the Cornell Research team,
[21:38.520 --> 21:40.880]  a good amount of us, are here on a weekly basis
[21:40.880 --> 21:45.160]  measuring height, diameter, getting leaf area,
[21:45.160 --> 21:47.660]  sampling, getting a lot of these measurements
[21:47.660 --> 21:50.880]  to really correlate and truth, right,
[21:50.880 --> 21:55.880]  our drone flight and our imagery that we get.
[21:55.960 --> 21:59.520]  We also aim to reconstruct individual plants,
[21:59.520 --> 22:01.400]  so creating individual plant models,
[22:01.400 --> 22:04.000]  and that would be with LiDAR sensors.
[22:04.000 --> 22:06.720]  I'm sure Kathleen went over what LiDAR sensors are,
[22:06.720 --> 22:11.720]  so yeah, do definitely reconstruct,
[22:12.320 --> 22:13.720]  sorry, flipping here,
[22:15.520 --> 22:17.320]  reconstruct individual plant models,
[22:17.320 --> 22:20.720]  and then with multispectral sensors,
[22:20.720 --> 22:22.720]  like I said, I'm sure she mentioned,
[22:22.720 --> 22:25.000]  to really evaluate vegetation indices.
[22:25.320 --> 22:27.280]  I'm sure she went over a couple of them already,
[22:27.280 --> 22:29.960]  so this makes it a great group to talk to,
[22:29.960 --> 22:33.880]  but essentially knowing those for plant health,
[22:33.880 --> 22:35.480]  knowing those for disease,
[22:35.480 --> 22:38.320]  knowing those for what my biomass might be
[22:38.320 --> 22:39.600]  at the end of the season,
[22:41.080 --> 22:42.960]  really just having a lot.
[22:42.960 --> 22:45.880]  So the goal is, yeah, reconstruct the models,
[22:45.880 --> 22:47.440]  evaluate the indices.
[22:47.440 --> 22:49.920]  Those taken together, essentially,
[22:49.920 --> 22:54.800]  would allow us to identify the optimal digital traits
[22:55.600 --> 22:57.800]  needed to gather that information
[22:57.800 --> 22:59.520]  in terms of yield estimation, right?
[22:59.520 --> 23:02.920]  So then we no longer have a Cornell hemp research team,
[23:02.920 --> 23:05.280]  crew coming out here on a week-to-week basis.
[23:05.280 --> 23:09.440]  We have a flight team, maybe of two to five, not a lot,
[23:09.440 --> 23:11.000]  doing this on a week-to-week basis,
[23:11.000 --> 23:14.640]  and sitting at their computer in nice, cool air
[23:14.640 --> 23:16.720]  instead of being out here on a hot day.
[23:18.400 --> 23:19.320]  With that, like I said,
[23:19.320 --> 23:21.200]  this is a very foundational trial for me,
[23:21.200 --> 23:26.200]  and so through this, I'm also exploring things like color,
[23:27.080 --> 23:28.400]  impacts of color,
[23:30.280 --> 23:34.560]  things like sex determination, chemotyping, right?
[23:34.560 --> 23:36.520]  Do I have a high THC plant?
[23:36.520 --> 23:38.320]  Do I have a high CBD plant?
[23:38.320 --> 23:40.320]  And flowering time.
[23:40.320 --> 23:42.880]  So these first two populations we have out here
[23:42.880 --> 23:43.920]  that I mentioned,
[23:44.800 --> 23:46.520]  you could see the variability in flowering time.
[23:46.520 --> 23:49.200]  We've had stuff starting in early July,
[23:49.200 --> 23:51.840]  and I'm sure we're still gonna get flowering
[23:51.840 --> 23:54.280]  starting like in October.
[23:54.280 --> 23:56.520]  So really doing that on a weekly basis
[23:56.520 --> 24:01.520]  would allow us to see what's going on with this population.
[24:02.560 --> 24:04.040]  Also too, we're getting genetic data,
[24:04.040 --> 24:06.120]  so that already confounds it a lot more
[24:06.120 --> 24:08.440]  and gives us more information that we need.
[24:08.440 --> 24:11.160]  And those last two populations down there
[24:11.160 --> 24:14.720]  are a basis for color exploration
[24:14.720 --> 24:17.680]  and kind of plant yield.
[24:19.520 --> 24:22.440]  But yeah, do we have any questions?
[24:29.250 --> 24:32.930]  Yes, so on a biweekly or week-to-week basis,
[24:32.930 --> 24:36.530]  we are collecting height data
[24:36.530 --> 24:40.170]  with a team of four to five people out here.
[24:40.170 --> 24:41.330]  And then with the drones,
[24:41.330 --> 24:42.650]  we're gonna be able to see
[24:42.650 --> 24:44.810]  and kind of correlate those height measurements
[24:44.810 --> 24:46.090]  with the drone measurements.
[24:46.090 --> 24:47.850]  And you can do that essentially
[24:47.850 --> 24:50.210]  with like a digital elevation model,
[24:50.450 --> 24:53.250]  a digital surface model of your field.
[24:53.250 --> 24:54.610]  And if you know your plant layout
[24:54.610 --> 24:55.770]  and have some kind of markers,
[24:55.770 --> 24:56.850]  so you'll see throughout the field,
[24:56.850 --> 24:59.010]  we have like these things called GCPs.
[24:59.010 --> 25:00.410]  They're like white tiles.
[25:00.410 --> 25:02.730]  And what that stands for is ground control points.
[25:02.730 --> 25:06.090]  And that allows us to not only overlay week by week
[25:06.090 --> 25:07.050]  for the same points,
[25:07.050 --> 25:09.730]  but say if we had those GCPs raised,
[25:09.730 --> 25:11.770]  it would allow us to benchmark that we know
[25:11.770 --> 25:14.130]  that this GCP is always at this height
[25:14.130 --> 25:15.850]  and if a plant is at this height.
[25:15.850 --> 25:20.850]  So another method to kind of really support
[25:21.770 --> 25:23.330]  what we're seeing in terms of height.
[25:23.330 --> 25:26.250]  Balance, you've got a plant a week ago
[25:26.250 --> 25:27.370]  that was standing straight up.
[25:27.370 --> 25:29.770]  You've got a lot of wind from the west, which I see.
[25:29.770 --> 25:30.610]  Yep.
[25:30.610 --> 25:32.810]  The plant's sitting at a 25 degree angle,
[25:32.810 --> 25:34.770]  so the height is actually less than it was.
[25:34.770 --> 25:38.010]  Correct, so the height actually is the,
[25:38.010 --> 25:39.930]  the height that we get on a week-to-week basis
[25:39.930 --> 25:41.730]  is the above ground level height,
[25:41.730 --> 25:43.370]  not the stem length
[25:43.410 --> 25:46.090]  or what the actual height of the plant would be.
[25:46.090 --> 25:46.930]  This is that.
[25:46.930 --> 25:48.010]  So measuring from the ground level
[25:48.010 --> 25:49.410]  to the apical stem level?
[25:49.410 --> 25:52.130]  Yeah, so for instance, if we come over here a bit,
[25:52.130 --> 25:54.570]  you can kind of see this one is a bit lodged.
[25:54.570 --> 25:57.850]  If I stood it up properly, that would be the height,
[25:57.850 --> 26:00.410]  but our height measurements on the week-to-week basis
[26:00.410 --> 26:03.170]  only goes from the above ground level
[26:03.170 --> 26:04.010]  because that's exactly.
[26:04.010 --> 26:04.970]  You're measuring it at that angle.
[26:04.970 --> 26:07.370]  Yep, that's exactly what the drone is gonna see.
[26:07.370 --> 26:09.610]  And then the nice thing about having it on a week-to-week,
[26:09.610 --> 26:11.290]  you can also, the nice thing with drones
[26:11.290 --> 26:13.250]  is you can also get percent lodging.
[26:14.170 --> 26:15.730]  They do that in a lot of other crops,
[26:15.730 --> 26:17.210]  so then we'll be able to know.
[26:17.210 --> 26:19.130]  But yeah, that is the one thing.
[26:19.130 --> 26:21.650]  You can't get what the actual potential height
[26:21.650 --> 26:23.250]  of the plant might be,
[26:23.250 --> 26:26.130]  but you can guesstimate it from accounting for lodging
[26:26.130 --> 26:28.210]  and the height that you're getting.
[26:29.530 --> 26:31.970]  How do you calculate the leaf area?
[26:31.970 --> 26:33.130]  The leaf area, yeah.
[26:33.130 --> 26:36.410]  So with leaf area, there's a leaf area index,
[26:36.410 --> 26:38.650]  and that's really done,
[26:38.650 --> 26:40.930]  yeah, they do it less with multispectral sensors
[26:41.570 --> 26:42.490]  and more with LIDAR sensors.
[26:42.490 --> 26:45.890]  And LIDAR sensors are the ones that is an active sensor
[26:45.890 --> 26:47.650]  that shoots lasers essentially,
[26:47.650 --> 26:50.570]  or just shoots a laser really, and scans.
[26:50.570 --> 26:54.330]  And so with that data, you can calculate leaf area index,
[26:54.330 --> 26:56.330]  but then there's also nice handheld tools
[26:56.330 --> 26:59.730]  that allow us to measure out in the field, right?
[26:59.730 --> 27:01.490]  We can go below canopy.
[27:01.490 --> 27:05.410]  There's a wand, also called an LAI, for the same purpose,
[27:05.410 --> 27:08.690]  and it will give us a measurement of the leaf area index.
[27:08.690 --> 27:13.650]  And then we can also do leaf samples on a weekly basis
[27:13.650 --> 27:16.370]  or at certain time points to get leaf area.
[27:16.370 --> 27:18.050]  What do you mean by the leaf sample?
[27:18.050 --> 27:20.090]  Yeah, just pick a leaf, right?
[27:20.090 --> 27:23.210]  And then try to keep it consistent throughout the field.
[27:23.210 --> 27:24.050]  You can scan it.
[27:24.050 --> 27:26.810]  So there's also tools to have like a flatbed scanner
[27:27.730 --> 27:28.770]  to scan the leaf.
[27:28.770 --> 27:32.610]  But yeah, I'm going to cut our conversation.
[27:32.610 --> 27:34.730]  We're gonna go over to the next session.
[27:34.730 --> 27:37.490]  And then I probably took a lot of your free time
[27:37.490 --> 27:38.330]  for after.
[27:43.930 --> 27:47.410]  This has been a production of Cornell University
[27:47.410 --> 27:50.250]  on the web at cornell.edu.
